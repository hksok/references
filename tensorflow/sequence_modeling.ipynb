{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence modelling \n",
    "\n",
    "## Coding tutorials\n",
    " #### [1.  The IMDb dataset](#coding_tutorial_1)\n",
    " #### [2. Padding and masking sequence data](#coding_tutorial_2)\n",
    " #### [3. The Embedding layer](#coding_tutorial_3)\n",
    " #### [4. The Embedding Projector](#coding_tutorial_4)\n",
    " #### [5. Recurrent neural network layers](#coding_tutorial_5)\n",
    " #### [6. Stacked RNNs and the Bidirectional wrapper](#coding_tutorial_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_1\"></a>\n",
    "## The IMDb Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import imdb\n",
    "\n",
    "import tensorflow.keras.datasets.imdb as imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and assign the data set using load_data()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the type of the data\n",
    "\n",
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the shape of the data\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 22665,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 21631,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 19193,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 10311,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 31050,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 12118,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first dataset element input\n",
    "# Notice encoding\n",
    "\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first dataset element output\n",
    "\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset with different options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
       "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
       " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
       "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
       "         list([1, 111, 748, 4368, 1133, 33782, 24563, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 10941, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 24563, 16, 53, 928, 11, 51278, 74, 4, 438, 21, 27, 10044, 589, 8, 22, 107, 20123, 19550, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 18995, 2425, 34, 12998, 8738, 48078, 5, 19353, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 27608, 1060, 63, 29, 93, 11, 5421, 11, 15236, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 19469, 10, 10, 4, 993, 45222, 7, 4, 1766, 2634, 2164, 24563, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 10760, 16, 6, 465, 993, 2006, 30995, 573, 17, 61862, 42, 4, 17345, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 10104, 146, 655, 2212, 5, 258, 12, 184, 10104, 546, 5, 849, 10333, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 10288, 5, 12141, 11, 661, 8, 339, 17863, 4, 2455, 11434, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 61862, 48414, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 68411, 25399, 18, 6, 711, 4, 9909, 26, 10296, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 25399, 18, 27, 173, 9, 2399, 17, 6, 12397, 428, 14657, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 13182, 54, 25399, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 17345, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 25399, 3292, 98, 6, 31036, 10, 10, 6639, 19, 14, 10241, 267, 162, 711, 37, 5900, 752, 98, 4, 17345, 2378, 90, 19, 6, 73284, 7, 36744, 1810, 77553, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 48414, 17, 15454, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 31036, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 21627, 5437, 33, 1526, 6, 425, 3155, 33697, 4535, 1636, 7, 4, 4669, 11966, 469, 4, 4552, 54, 4, 150, 5664, 17345, 280, 53, 68411, 25399, 18, 339, 29, 1978, 27, 7885, 5, 17303, 68, 1830, 19, 6571, 14605, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 28228, 33, 4, 5673, 7, 15, 18760, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 12214, 44, 148, 687, 24563, 203, 42, 203, 24, 28, 69, 32157, 6676, 11, 330, 54, 29, 93, 61862, 21, 845, 14148, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 14967, 787, 7, 2460, 19569, 61862, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 15205, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
       "         ...,\n",
       "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
       "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset with defaults\n",
    "\n",
    "imdb.load_data(path='imdb.npz',\n",
    "               index_from=3)\n",
    "\n",
    "# ~/.keras/dataset/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
       "         list([1, 194, 2, 194, 2, 78, 228, 5, 6, 2, 2, 2, 134, 26, 4, 715, 8, 118, 2, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 2, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2, 2, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 2, 4, 118, 9, 4, 130, 2, 19, 4, 2, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 2, 2, 398, 4, 2, 26, 2, 5, 163, 11, 2, 2, 4, 2, 9, 194, 775, 7, 2, 2, 349, 2, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 5, 4, 228, 9, 43, 2, 2, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 2, 228, 2, 5, 2, 656, 245, 2, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 9, 6, 371, 78, 22, 625, 64, 2, 9, 8, 168, 145, 23, 4, 2, 15, 16, 4, 2, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 4, 86, 320, 35, 534, 19, 263, 2, 2, 4, 2, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 2, 43, 645, 662, 8, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 780, 8, 106, 14, 2, 2, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2, 51, 9, 170, 23, 595, 116, 595, 2, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 11, 6, 230, 245, 2, 9, 6, 2, 446, 2, 45, 2, 84, 2, 2, 21, 4, 912, 84, 2, 325, 725, 134, 2, 2, 84, 5, 36, 28, 57, 2, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 2, 14, 9, 31, 7, 4, 2, 2, 2, 2, 2, 18, 6, 20, 207, 110, 563, 12, 8, 2, 2, 8, 97, 6, 20, 53, 2, 74, 4, 460, 364, 2, 29, 270, 11, 960, 108, 45, 40, 29, 2, 395, 11, 6, 2, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 2, 11, 4, 2, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2, 234, 2, 2, 7, 496, 4, 139, 929, 2, 2, 2, 5, 2, 18, 4, 2, 2, 250, 11, 2, 2, 4, 2, 2, 747, 2, 372, 2, 2, 541, 2, 7, 4, 59, 2, 4, 2, 2]),\n",
       "         list([1, 2, 2, 69, 72, 2, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 2, 51, 575, 32, 61, 369, 71, 66, 770, 12, 2, 75, 100, 2, 8, 4, 105, 37, 69, 147, 712, 75, 2, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 2, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 4, 719, 2, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2, 101, 405, 39, 14, 2, 4, 2, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 2, 2, 9, 24, 6, 78, 2, 17, 2, 2, 21, 27, 2, 2, 5, 2, 2, 92, 2, 4, 2, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 2, 2, 9, 6, 66, 78, 2, 4, 631, 2, 5, 2, 272, 191, 2, 6, 2, 8, 2, 2, 2, 544, 5, 383, 2, 848, 2, 2, 497, 2, 8, 2, 2, 2, 21, 60, 27, 239, 9, 43, 2, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 2, 72, 7, 51, 6, 2, 22, 4, 204, 131, 9])],\n",
       "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
       " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 2, 394, 354, 4, 123, 9, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 6, 717]),\n",
       "         list([1, 14, 22, 2, 6, 176, 7, 2, 88, 12, 2, 23, 2, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 2, 2, 4, 2, 2, 109, 2, 21, 4, 22, 2, 8, 6, 2, 2, 10, 10, 4, 105, 987, 35, 841, 2, 19, 861, 2, 5, 2, 2, 45, 55, 221, 15, 670, 2, 526, 14, 2, 4, 405, 5, 2, 7, 27, 85, 108, 131, 4, 2, 2, 2, 405, 9, 2, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 2, 2, 45, 407, 31, 7, 41, 2, 105, 21, 59, 299, 12, 38, 950, 5, 2, 15, 45, 629, 488, 2, 127, 6, 52, 292, 17, 4, 2, 185, 132, 2, 2, 2, 488, 2, 47, 6, 392, 173, 4, 2, 2, 270, 2, 4, 2, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2, 7, 2, 861, 2, 5, 2, 30, 2, 2, 56, 4, 841, 5, 990, 692, 8, 4, 2, 398, 229, 10, 10, 13, 2, 670, 2, 14, 9, 31, 7, 27, 111, 108, 15, 2, 19, 2, 2, 875, 551, 14, 22, 9, 2, 21, 45, 2, 5, 45, 252, 8, 2, 6, 565, 921, 2, 39, 4, 529, 48, 25, 181, 8, 67, 35, 2, 22, 49, 238, 60, 135, 2, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 2, 25, 203, 28, 8, 818, 12, 125, 4, 2]),\n",
       "         list([1, 111, 748, 2, 2, 2, 2, 4, 87, 2, 2, 7, 31, 318, 2, 7, 4, 498, 2, 748, 63, 29, 2, 220, 686, 2, 5, 17, 12, 575, 220, 2, 17, 6, 185, 132, 2, 16, 53, 928, 11, 2, 74, 4, 438, 21, 27, 2, 589, 8, 22, 107, 2, 2, 997, 2, 8, 35, 2, 2, 11, 22, 231, 54, 29, 2, 29, 100, 2, 2, 34, 2, 2, 2, 5, 2, 98, 31, 2, 33, 6, 58, 14, 2, 2, 8, 4, 365, 7, 2, 2, 356, 346, 4, 2, 2, 63, 29, 93, 11, 2, 11, 2, 33, 6, 58, 54, 2, 431, 748, 7, 32, 2, 16, 11, 94, 2, 10, 10, 4, 993, 2, 7, 4, 2, 2, 2, 2, 8, 847, 8, 2, 121, 31, 7, 27, 86, 2, 2, 16, 6, 465, 993, 2, 2, 573, 17, 2, 42, 4, 2, 37, 473, 6, 711, 6, 2, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 2, 53, 33, 2, 2, 37, 70, 2, 4, 2, 2, 74, 476, 37, 62, 91, 2, 169, 4, 2, 2, 146, 655, 2, 5, 258, 12, 184, 2, 546, 5, 849, 2, 7, 4, 22, 2, 18, 631, 2, 797, 7, 4, 2, 71, 348, 425, 2, 2, 19, 2, 5, 2, 11, 661, 8, 339, 2, 4, 2, 2, 7, 4, 2, 10, 10, 263, 787, 9, 270, 11, 6, 2, 4, 2, 2, 121, 4, 2, 26, 2, 19, 68, 2, 5, 28, 446, 6, 318, 2, 8, 67, 51, 36, 70, 81, 8, 2, 2, 36, 2, 8, 2, 2, 18, 6, 711, 4, 2, 26, 2, 2, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 2, 2, 168, 2, 2, 137, 2, 18, 27, 173, 9, 2, 17, 6, 2, 428, 2, 232, 11, 4, 2, 37, 272, 40, 2, 247, 30, 656, 6, 2, 54, 2, 2, 98, 6, 2, 40, 558, 37, 2, 98, 4, 2, 2, 15, 14, 9, 57, 2, 5, 2, 6, 275, 711, 2, 2, 2, 98, 6, 2, 10, 10, 2, 19, 14, 2, 267, 162, 711, 37, 2, 752, 98, 4, 2, 2, 90, 19, 6, 2, 7, 2, 2, 2, 4, 2, 2, 930, 8, 508, 90, 4, 2, 8, 4, 2, 17, 2, 2, 2, 4, 2, 8, 2, 189, 4, 2, 2, 2, 4, 2, 5, 95, 271, 23, 6, 2, 2, 2, 2, 33, 2, 6, 425, 2, 2, 2, 2, 7, 4, 2, 2, 469, 4, 2, 54, 4, 150, 2, 2, 280, 53, 2, 2, 18, 339, 29, 2, 27, 2, 5, 2, 68, 2, 19, 2, 2, 4, 2, 7, 263, 65, 2, 34, 6, 2, 2, 43, 159, 29, 9, 2, 9, 387, 73, 195, 584, 10, 10, 2, 4, 58, 810, 54, 14, 2, 117, 22, 16, 93, 5, 2, 4, 192, 15, 12, 16, 93, 34, 6, 2, 2, 33, 4, 2, 7, 15, 2, 2, 2, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 2, 7, 819, 4, 22, 2, 17, 6, 2, 787, 7, 2, 2, 2, 100, 30, 4, 2, 2, 2, 2, 42, 2, 11, 4, 2, 42, 101, 704, 7, 101, 999, 15, 2, 94, 2, 180, 5, 9, 2, 34, 2, 45, 6, 2, 22, 60, 6, 2, 31, 11, 94, 2, 96, 21, 94, 749, 9, 57, 975]),\n",
       "         ...,\n",
       "         list([1, 13, 2, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 2, 21, 45, 184, 78, 4, 2, 910, 769, 2, 2, 395, 2, 5, 2, 11, 119, 2, 89, 2, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2, 284, 2, 2, 37, 315, 4, 226, 20, 272, 2, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 2]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 2, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2, 7, 743, 46, 2, 9, 2, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 2, 5, 9, 2, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 2, 92, 124, 51, 45, 2, 71, 536, 13, 520, 14, 20, 6, 2, 7, 470]),\n",
       "         list([1, 6, 52, 2, 430, 22, 9, 220, 2, 8, 28, 2, 519, 2, 6, 769, 15, 47, 6, 2, 2, 8, 114, 5, 33, 222, 31, 55, 184, 704, 2, 2, 19, 346, 2, 5, 6, 364, 350, 4, 184, 2, 9, 133, 2, 11, 2, 2, 21, 4, 2, 2, 570, 50, 2, 2, 9, 6, 2, 17, 6, 2, 2, 21, 17, 6, 2, 232, 2, 2, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 2, 19, 4, 78, 173, 7, 27, 2, 2, 2, 718, 2, 9, 6, 2, 17, 210, 5, 2, 2, 47, 77, 395, 14, 172, 173, 18, 2, 2, 2, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 2, 53, 40, 35, 390, 7, 11, 4, 2, 7, 4, 314, 74, 6, 792, 22, 2, 19, 714, 727, 2, 382, 4, 91, 2, 439, 19, 14, 20, 9, 2, 2, 2, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2, 2])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit the vocabulary to the top 500 words using num_words\n",
    "\n",
    "imdb.load_data(num_words=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([list([2, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 2, 173, 36, 256, 2, 25, 100, 43, 838, 112, 50, 670, 2, 2, 35, 480, 284, 2, 150, 2, 172, 112, 167, 2, 336, 385, 39, 2, 172, 2, 2, 17, 546, 38, 13, 447, 2, 192, 50, 16, 2, 147, 2, 19, 14, 22, 2, 2, 2, 469, 2, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 2, 22, 17, 515, 17, 12, 16, 626, 18, 2, 2, 62, 386, 12, 2, 316, 2, 106, 2, 2, 2, 2, 16, 480, 66, 2, 33, 2, 130, 12, 16, 38, 619, 2, 25, 124, 51, 36, 135, 48, 25, 2, 33, 2, 22, 12, 215, 28, 77, 52, 2, 14, 407, 16, 82, 2, 2, 2, 107, 117, 2, 15, 256, 2, 2, 2, 2, 2, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 2, 2, 2, 2, 13, 104, 88, 2, 381, 15, 297, 98, 32, 2, 56, 26, 141, 2, 194, 2, 18, 2, 226, 22, 21, 134, 476, 26, 480, 2, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 2, 226, 65, 16, 38, 2, 88, 12, 16, 283, 2, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
       "         list([2, 194, 2, 194, 2, 78, 228, 2, 2, 2, 2, 2, 134, 26, 2, 715, 2, 118, 2, 14, 394, 20, 13, 119, 954, 189, 102, 2, 207, 110, 2, 21, 14, 69, 188, 2, 30, 23, 2, 2, 249, 126, 93, 2, 114, 2, 2, 2, 2, 647, 2, 116, 2, 35, 2, 2, 229, 2, 340, 2, 2, 118, 2, 2, 130, 2, 19, 2, 2, 2, 89, 29, 952, 46, 37, 2, 455, 2, 45, 43, 38, 2, 2, 398, 2, 2, 26, 2, 2, 163, 11, 2, 2, 2, 2, 2, 194, 775, 2, 2, 2, 349, 2, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 2, 2, 228, 2, 43, 2, 2, 15, 299, 120, 2, 120, 174, 11, 220, 175, 136, 50, 2, 2, 228, 2, 2, 2, 656, 245, 2, 2, 2, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 2, 2, 371, 78, 22, 625, 64, 2, 2, 2, 168, 145, 23, 2, 2, 15, 16, 2, 2, 2, 28, 2, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([2, 14, 47, 2, 30, 31, 2, 2, 249, 108, 2, 2, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 2, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 2, 86, 320, 35, 534, 19, 263, 2, 2, 2, 2, 33, 89, 78, 12, 66, 16, 2, 360, 2, 2, 58, 316, 334, 11, 2, 2, 43, 645, 662, 2, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 780, 2, 106, 14, 2, 2, 18, 2, 22, 12, 215, 28, 610, 40, 2, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 2, 22, 47, 2, 2, 51, 2, 170, 23, 595, 116, 595, 2, 13, 191, 79, 638, 89, 2, 14, 2, 2, 106, 607, 624, 35, 534, 2, 227, 2, 129, 113]),\n",
       "         ...,\n",
       "         list([2, 11, 2, 230, 245, 2, 2, 2, 2, 446, 2, 45, 2, 84, 2, 2, 21, 2, 912, 84, 2, 325, 725, 134, 2, 2, 84, 2, 36, 28, 57, 2, 21, 2, 140, 2, 703, 2, 2, 84, 56, 18, 2, 14, 2, 31, 2, 2, 2, 2, 2, 2, 2, 18, 2, 20, 207, 110, 563, 12, 2, 2, 2, 2, 97, 2, 20, 53, 2, 74, 2, 460, 364, 2, 29, 270, 11, 960, 108, 45, 40, 29, 2, 395, 11, 2, 2, 500, 2, 2, 89, 364, 70, 29, 140, 2, 64, 2, 11, 2, 2, 26, 178, 2, 529, 443, 2, 2, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 2, 65, 496, 2, 231, 2, 790, 2, 2, 320, 234, 2, 234, 2, 2, 2, 496, 2, 139, 929, 2, 2, 2, 2, 2, 18, 2, 2, 2, 250, 11, 2, 2, 2, 2, 2, 747, 2, 372, 2, 2, 541, 2, 2, 2, 59, 2, 2, 2, 2]),\n",
       "         list([2, 2, 2, 69, 72, 2, 13, 610, 930, 2, 12, 582, 23, 2, 16, 484, 685, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 2, 62, 30, 145, 402, 11, 2, 51, 575, 32, 61, 369, 71, 66, 770, 12, 2, 75, 100, 2, 2, 2, 105, 37, 69, 147, 712, 75, 2, 44, 257, 390, 2, 69, 263, 514, 105, 50, 286, 2, 23, 2, 123, 13, 161, 40, 2, 421, 2, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 2, 719, 2, 13, 18, 31, 62, 40, 2, 2, 2, 2, 2, 14, 123, 2, 942, 25, 2, 721, 12, 145, 2, 202, 12, 160, 580, 202, 12, 2, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 2, 15, 251, 2, 2, 12, 38, 84, 80, 124, 12, 2, 23]),\n",
       "         list([2, 17, 2, 194, 337, 2, 2, 204, 22, 45, 254, 2, 106, 14, 123, 2, 2, 270, 2, 2, 2, 2, 732, 2, 101, 405, 39, 14, 2, 2, 2, 2, 115, 50, 305, 12, 47, 2, 168, 2, 235, 2, 38, 111, 699, 102, 2, 2, 2, 2, 2, 24, 2, 78, 2, 17, 2, 2, 21, 27, 2, 2, 2, 2, 2, 92, 2, 2, 2, 2, 2, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 2, 97, 12, 157, 21, 2, 2, 2, 2, 66, 78, 2, 2, 631, 2, 2, 2, 272, 191, 2, 2, 2, 2, 2, 2, 2, 544, 2, 383, 2, 848, 2, 2, 497, 2, 2, 2, 2, 2, 21, 60, 27, 239, 2, 43, 2, 209, 405, 10, 10, 12, 764, 40, 2, 248, 20, 12, 16, 2, 174, 2, 72, 2, 51, 2, 2, 22, 2, 204, 131, 2])],\n",
       "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
       " (array([list([2, 591, 202, 14, 31, 2, 717, 10, 10, 2, 2, 2, 2, 360, 2, 2, 177, 2, 394, 354, 2, 123, 2, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 2, 124, 14, 286, 170, 2, 157, 46, 2, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 2, 717]),\n",
       "         list([2, 14, 22, 2, 2, 176, 2, 2, 88, 12, 2, 23, 2, 2, 109, 943, 2, 114, 2, 55, 606, 2, 111, 2, 2, 139, 193, 273, 23, 2, 172, 270, 11, 2, 2, 2, 2, 2, 109, 2, 21, 2, 22, 2, 2, 2, 2, 2, 10, 10, 2, 105, 987, 35, 841, 2, 19, 861, 2, 2, 2, 2, 45, 55, 221, 15, 670, 2, 526, 14, 2, 2, 405, 2, 2, 2, 27, 85, 108, 131, 2, 2, 2, 2, 405, 2, 2, 133, 2, 50, 13, 104, 51, 66, 166, 14, 22, 157, 2, 2, 530, 239, 34, 2, 2, 45, 407, 31, 2, 41, 2, 105, 21, 59, 299, 12, 38, 950, 2, 2, 15, 45, 629, 488, 2, 127, 2, 52, 292, 17, 2, 2, 185, 132, 2, 2, 2, 488, 2, 47, 2, 392, 173, 2, 2, 2, 270, 2, 2, 2, 2, 2, 65, 55, 73, 11, 346, 14, 20, 2, 2, 976, 2, 2, 2, 861, 2, 2, 2, 30, 2, 2, 56, 2, 841, 2, 990, 692, 2, 2, 2, 398, 229, 10, 10, 13, 2, 670, 2, 14, 2, 31, 2, 27, 111, 108, 15, 2, 19, 2, 2, 875, 551, 14, 22, 2, 2, 21, 45, 2, 2, 45, 252, 2, 2, 2, 565, 921, 2, 39, 2, 529, 48, 25, 181, 2, 67, 35, 2, 22, 49, 238, 60, 135, 2, 14, 2, 290, 2, 58, 10, 10, 472, 45, 55, 878, 2, 169, 11, 374, 2, 25, 203, 28, 2, 818, 12, 125, 2, 2]),\n",
       "         list([2, 111, 748, 2, 2, 2, 2, 2, 87, 2, 2, 2, 31, 318, 2, 2, 2, 498, 2, 748, 63, 29, 2, 220, 686, 2, 2, 17, 12, 575, 220, 2, 17, 2, 185, 132, 2, 16, 53, 928, 11, 2, 74, 2, 438, 21, 27, 2, 589, 2, 22, 107, 2, 2, 997, 2, 2, 35, 2, 2, 11, 22, 231, 54, 29, 2, 29, 100, 2, 2, 34, 2, 2, 2, 2, 2, 98, 31, 2, 33, 2, 58, 14, 2, 2, 2, 2, 365, 2, 2, 2, 356, 346, 2, 2, 2, 63, 29, 93, 11, 2, 11, 2, 33, 2, 58, 54, 2, 431, 748, 2, 32, 2, 16, 11, 94, 2, 10, 10, 2, 993, 2, 2, 2, 2, 2, 2, 2, 2, 847, 2, 2, 121, 31, 2, 27, 86, 2, 2, 16, 2, 465, 993, 2, 2, 573, 17, 2, 42, 2, 2, 37, 473, 2, 711, 2, 2, 2, 328, 212, 70, 30, 258, 11, 220, 32, 2, 108, 21, 133, 12, 2, 55, 465, 849, 2, 53, 33, 2, 2, 37, 70, 2, 2, 2, 2, 74, 476, 37, 62, 91, 2, 169, 2, 2, 2, 146, 655, 2, 2, 258, 12, 184, 2, 546, 2, 849, 2, 2, 2, 22, 2, 18, 631, 2, 797, 2, 2, 2, 71, 348, 425, 2, 2, 19, 2, 2, 2, 11, 661, 2, 339, 2, 2, 2, 2, 2, 2, 2, 10, 10, 263, 787, 2, 270, 11, 2, 2, 2, 2, 2, 121, 2, 2, 26, 2, 19, 68, 2, 2, 28, 446, 2, 318, 2, 2, 67, 51, 36, 70, 81, 2, 2, 2, 36, 2, 2, 2, 2, 18, 2, 711, 2, 2, 26, 2, 2, 11, 14, 636, 720, 12, 426, 28, 77, 776, 2, 97, 38, 111, 2, 2, 168, 2, 2, 137, 2, 18, 27, 173, 2, 2, 17, 2, 2, 428, 2, 232, 11, 2, 2, 37, 272, 40, 2, 247, 30, 656, 2, 2, 54, 2, 2, 98, 2, 2, 40, 558, 37, 2, 98, 2, 2, 2, 15, 14, 2, 57, 2, 2, 2, 2, 275, 711, 2, 2, 2, 98, 2, 2, 10, 10, 2, 19, 14, 2, 267, 162, 711, 37, 2, 752, 98, 2, 2, 2, 90, 19, 2, 2, 2, 2, 2, 2, 2, 2, 2, 930, 2, 508, 90, 2, 2, 2, 2, 2, 17, 2, 2, 2, 2, 2, 2, 2, 189, 2, 2, 2, 2, 2, 2, 2, 95, 271, 23, 2, 2, 2, 2, 2, 33, 2, 2, 425, 2, 2, 2, 2, 2, 2, 2, 2, 469, 2, 2, 54, 2, 150, 2, 2, 280, 53, 2, 2, 18, 339, 29, 2, 27, 2, 2, 2, 68, 2, 19, 2, 2, 2, 2, 2, 263, 65, 2, 34, 2, 2, 2, 43, 159, 29, 2, 2, 2, 387, 73, 195, 584, 10, 10, 2, 2, 58, 810, 54, 14, 2, 117, 22, 16, 93, 2, 2, 2, 192, 15, 12, 16, 93, 34, 2, 2, 2, 33, 2, 2, 2, 15, 2, 2, 2, 325, 12, 62, 30, 776, 2, 67, 14, 17, 2, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 2, 2, 819, 2, 22, 2, 17, 2, 2, 787, 2, 2, 2, 2, 100, 30, 2, 2, 2, 2, 2, 42, 2, 11, 2, 2, 42, 101, 704, 2, 101, 999, 15, 2, 94, 2, 180, 2, 2, 2, 34, 2, 45, 2, 2, 22, 60, 2, 2, 31, 11, 94, 2, 96, 21, 94, 749, 2, 57, 975]),\n",
       "         ...,\n",
       "         list([2, 13, 2, 15, 2, 135, 14, 2, 35, 32, 46, 394, 20, 62, 30, 2, 21, 45, 184, 78, 2, 2, 910, 769, 2, 2, 395, 2, 2, 2, 11, 119, 2, 89, 2, 2, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 2, 185, 2, 284, 2, 2, 37, 315, 2, 226, 20, 272, 2, 40, 29, 152, 60, 181, 2, 30, 50, 553, 362, 80, 119, 12, 21, 846, 2]),\n",
       "         list([2, 11, 119, 241, 2, 2, 840, 20, 12, 468, 15, 94, 2, 562, 791, 39, 2, 86, 107, 2, 97, 14, 31, 33, 2, 2, 2, 743, 46, 2, 2, 2, 2, 2, 768, 47, 2, 79, 90, 145, 164, 162, 50, 2, 501, 119, 2, 2, 2, 78, 232, 15, 16, 224, 11, 2, 333, 20, 2, 985, 200, 2, 2, 2, 2, 2, 2, 79, 357, 2, 20, 47, 220, 57, 206, 139, 11, 12, 2, 55, 117, 212, 13, 2, 92, 124, 51, 45, 2, 71, 536, 13, 520, 14, 20, 2, 2, 2, 470]),\n",
       "         list([2, 2, 52, 2, 430, 22, 2, 220, 2, 2, 28, 2, 519, 2, 2, 769, 15, 47, 2, 2, 2, 2, 114, 2, 33, 222, 31, 55, 184, 704, 2, 2, 19, 346, 2, 2, 2, 364, 350, 2, 184, 2, 2, 133, 2, 11, 2, 2, 21, 2, 2, 2, 570, 50, 2, 2, 2, 2, 2, 17, 2, 2, 2, 21, 17, 2, 2, 232, 2, 2, 29, 266, 56, 96, 346, 194, 308, 2, 194, 21, 29, 218, 2, 19, 2, 78, 173, 2, 27, 2, 2, 2, 718, 2, 2, 2, 2, 17, 210, 2, 2, 2, 47, 77, 395, 14, 172, 173, 18, 2, 2, 2, 82, 127, 27, 173, 11, 2, 392, 217, 21, 50, 2, 57, 65, 12, 2, 53, 40, 35, 390, 2, 11, 2, 2, 2, 2, 314, 74, 2, 792, 22, 2, 19, 714, 727, 2, 382, 2, 91, 2, 439, 19, 14, 20, 2, 2, 2, 2, 2, 756, 25, 124, 2, 31, 12, 16, 93, 804, 34, 2, 2])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ignore the top 10 most frequent words using skip_top\n",
    "\n",
    "imdb.load_data(skip_top=10, num_words=1000, oov_char=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 518, 21, 55, 1713, 6, 20, 716, 6, 65, 38, 73, 15, 12, 220, 461, 878, 14, 20, 716, 450, 537, 38, 73, 5189, 15, 12, 16, 4, 86, 171, 211, 6, 20, 13, 100, 24, 106, 8, 20252, 12, 16, 99, 147, 5, 4, 105, 38, 565, 15, 149, 12, 877, 6, 965, 1651, 319, 134, 289, 349, 5, 68, 2166, 855, 19, 68, 10082, 31, 11, 843, 400, 569, 72, 99, 254, 150, 13, 28, 296, 11, 94, 6274, 209, 21501, 450, 211, 5, 13, 923, 51, 13, 210, 6677, 14, 20, 9, 6, 991, 4, 487, 4, 116, 4, 10409, 7, 450, 537, 209, 112, 60, 4, 222, 227, 5303, 285, 44, 14, 20, 9, 3160, 1542, 1809, 2128, 57, 594, 12, 434, 215, 28, 1816, 98]),\n",
       "         list([1, 14, 22, 714, 8012, 4, 921, 2124, 4, 905, 1488, 5, 4, 350, 2501, 354, 7, 1691, 1612, 349, 13, 1610, 12, 23, 6, 13574, 5, 16, 2664, 15, 13, 69, 24, 557, 7, 12, 159, 10, 10, 13, 81, 24, 124, 48, 14, 16, 14513, 3667, 2016, 21, 4, 1794, 4, 8466, 5, 943, 7, 4, 105, 17, 73, 17, 4, 49, 1096, 370, 157, 3392, 4, 109, 33241, 299, 32, 1467, 6, 1249, 744, 10, 10, 4, 8466, 200, 1593, 5, 14513, 1367, 4, 172, 389, 1175, 75, 219, 11, 1513, 890, 19, 1593, 5, 1441, 6909, 6239, 9, 389, 11, 41, 105, 1302, 4182, 5, 13291, 6, 8022, 23, 41, 105, 11, 33, 297, 11, 4, 5322, 7, 4, 1635, 59, 9, 2227, 5, 246, 31, 70, 9530, 19, 41, 33, 4, 172, 58, 10, 10, 50, 26, 49, 388, 121, 13, 235, 4, 114, 9281, 6, 1229, 5, 4, 388, 200, 33241, 5, 27, 1233, 980, 220, 306, 398, 18, 160, 22, 33241, 266, 125, 17, 160, 109, 32, 295, 21, 148, 26, 1403, 5266, 10, 10, 14, 22, 215, 30, 448, 23, 6, 283, 65, 42, 215, 28, 77, 398, 34, 294, 37, 1452, 134, 2490, 13, 967, 12, 709, 46, 7, 6, 878, 158, 10, 10]),\n",
       "         list([1, 13, 219, 14, 20, 23, 248, 5, 447, 12, 13, 244, 6, 147, 1690, 22, 337, 5, 14, 31, 16, 87, 4, 177, 16, 93, 7, 49, 66, 221, 84, 8246, 9, 210, 87, 5, 1024, 31711, 9, 11, 6, 2756, 7, 27, 205, 29, 70, 297, 199, 212, 5, 708, 11, 4, 172, 20, 40, 171, 409, 70, 4, 65, 347, 9, 87, 99, 4, 197, 7, 112, 502, 8, 794, 6, 58, 347, 7, 51, 80, 593, 5, 8, 361, 14, 58, 347, 8, 3621, 6, 4564, 1690, 9, 35, 221, 326, 5, 14, 20, 961, 12, 46, 11, 141, 6, 96, 15, 9, 220, 484, 867])],\n",
       "        dtype=object), array([1, 0, 0, ..., 1, 1, 1])),\n",
       " (array([list([1, 14, 9, 31, 7, 4, 249, 108, 13, 28, 110, 11, 6, 137, 10, 10, 4, 439, 9, 15, 12, 152, 124, 726, 12, 494, 8, 30, 35, 1089, 993, 22, 43675, 42, 35, 3435, 9, 10528, 17, 6, 959, 12, 996, 23, 32, 6566, 10, 10, 4, 116, 9, 2526, 4, 2559, 125, 1489, 5, 4, 424, 3881, 1149, 10, 10, 14746, 8035, 9, 242, 4, 118, 155, 44, 14, 22, 21, 15, 218, 6, 52, 155, 252, 29, 47, 35, 1596, 5, 61226, 168, 21, 1116, 29, 191, 165, 511, 43, 168, 33, 89, 29, 12482, 54, 27, 4727, 889, 10, 10, 66, 92, 106, 14, 22, 49, 135, 12, 738, 3260, 4719, 13, 135, 31, 9, 99, 111]),\n",
       "         list([1, 4, 7591, 248, 7, 108, 5077, 28, 13, 421, 38, 117, 11728, 8, 105, 5077, 28, 13, 77, 93, 8, 4032, 34, 141, 3648, 414, 15670, 1316, 3264, 7678, 28837, 2161, 8464, 2986, 732, 12435, 61019, 46432, 798, 14, 22, 17, 48, 12, 71, 129, 24558]),\n",
       "         list([1, 160, 12576, 212, 270, 11, 4, 1547, 12, 186, 15, 4, 612, 31, 1622, 1466, 18, 1205, 16, 11, 14, 172, 719, 1547, 17, 38, 111, 7, 12563, 5, 71375, 108, 26, 270, 50, 5, 137, 14, 9, 246, 160, 31, 12, 9, 275, 195, 5, 73, 93, 15, 13, 131, 510, 12, 10, 10, 16866, 9, 928, 11, 6, 1155, 74, 644, 267, 5, 116, 7376, 30258, 13, 104, 442, 424, 8, 30, 6, 117, 1155, 151, 11, 41, 3992, 523, 59, 9, 99, 185, 8, 30, 928, 11, 349, 73, 16866, 127, 24, 1497, 41, 1417, 5, 515, 29, 5, 7376, 521, 245, 18, 49, 1356, 253, 183, 79, 2732, 54, 4, 3992, 106, 9, 2586, 16866, 659, 12, 5, 408, 12, 8, 7376, 17, 6, 3470, 5, 111, 712, 959, 10, 10, 542, 1794, 5, 4, 192, 15, 14, 20, 122, 24, 5390, 99, 76, 23, 706, 2764, 21, 6, 3793, 114, 97, 14, 6, 1036, 5, 737, 117, 22]),\n",
       "         ...,\n",
       "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
       "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
       "        dtype=object),\n",
       "  array([0, 0, 1, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit the sequence lengths to 500 using maxlen\n",
    "\n",
    "imdb.load_data(maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
       "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
       " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
       "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
       "         list([1, 111, 748, 4368, 1133, 33782, 24563, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 10941, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 24563, 16, 53, 928, 11, 51278, 74, 4, 438, 21, 27, 10044, 589, 8, 22, 107, 20123, 19550, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 18995, 2425, 34, 12998, 8738, 48078, 5, 19353, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 27608, 1060, 63, 29, 93, 11, 5421, 11, 15236, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 19469, 10, 10, 4, 993, 45222, 7, 4, 1766, 2634, 2164, 24563, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 10760, 16, 6, 465, 993, 2006, 30995, 573, 17, 61862, 42, 4, 17345, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 10104, 146, 655, 2212, 5, 258, 12, 184, 10104, 546, 5, 849, 10333, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 10288, 5, 12141, 11, 661, 8, 339, 17863, 4, 2455, 11434, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 61862, 48414, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 68411, 25399, 18, 6, 711, 4, 9909, 26, 10296, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 25399, 18, 27, 173, 9, 2399, 17, 6, 12397, 428, 14657, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 13182, 54, 25399, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 17345, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 25399, 3292, 98, 6, 31036, 10, 10, 6639, 19, 14, 10241, 267, 162, 711, 37, 5900, 752, 98, 4, 17345, 2378, 90, 19, 6, 73284, 7, 36744, 1810, 77553, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 48414, 17, 15454, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 31036, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 21627, 5437, 33, 1526, 6, 425, 3155, 33697, 4535, 1636, 7, 4, 4669, 11966, 469, 4, 4552, 54, 4, 150, 5664, 17345, 280, 53, 68411, 25399, 18, 339, 29, 1978, 27, 7885, 5, 17303, 68, 1830, 19, 6571, 14605, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 28228, 33, 4, 5673, 7, 15, 18760, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 12214, 44, 148, 687, 24563, 203, 42, 203, 24, 28, 69, 32157, 6676, 11, 330, 54, 29, 93, 61862, 21, 845, 14148, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 14967, 787, 7, 2460, 19569, 61862, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 15205, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
       "         ...,\n",
       "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
       "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use '1' as the character that indicates the start of a sequence\n",
    "\n",
    "imdb.load_data(start_char=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the dataset word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the imdb word index using get_word_index()\n",
    "\n",
    "imdb_word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the word index as a dictionary,\n",
    "# accounting for index_from.\n",
    "\n",
    "index_from = 3\n",
    "imdb_word_index = {key: value + index_from for key, value in imdb_word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52256"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve a specific word's index\n",
    "\n",
    "imdb_word_index['simpsonian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'film',\n",
       " 'was',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'casting',\n",
       " 'location',\n",
       " 'scenery',\n",
       " 'story',\n",
       " 'direction',\n",
       " \"everyone's\",\n",
       " 'really',\n",
       " 'suited',\n",
       " 'the',\n",
       " 'part',\n",
       " 'they',\n",
       " 'played',\n",
       " 'and',\n",
       " 'you',\n",
       " 'could',\n",
       " 'just',\n",
       " 'imagine',\n",
       " 'being',\n",
       " 'there',\n",
       " 'robert',\n",
       " \"redford's\",\n",
       " 'is',\n",
       " 'an',\n",
       " 'amazing',\n",
       " 'actor',\n",
       " 'and',\n",
       " 'now',\n",
       " 'the',\n",
       " 'same',\n",
       " 'being',\n",
       " 'director',\n",
       " \"norman's\",\n",
       " 'father',\n",
       " 'came',\n",
       " 'from',\n",
       " 'the',\n",
       " 'same',\n",
       " 'scottish',\n",
       " 'island',\n",
       " 'as',\n",
       " 'myself',\n",
       " 'so',\n",
       " 'i',\n",
       " 'loved',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'there',\n",
       " 'was',\n",
       " 'a',\n",
       " 'real',\n",
       " 'connection',\n",
       " 'with',\n",
       " 'this',\n",
       " 'film',\n",
       " 'the',\n",
       " 'witty',\n",
       " 'remarks',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'film',\n",
       " 'were',\n",
       " 'great',\n",
       " 'it',\n",
       " 'was',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'so',\n",
       " 'much',\n",
       " 'that',\n",
       " 'i',\n",
       " 'bought',\n",
       " 'the',\n",
       " 'film',\n",
       " 'as',\n",
       " 'soon',\n",
       " 'as',\n",
       " 'it',\n",
       " 'was',\n",
       " 'released',\n",
       " 'for',\n",
       " 'retail',\n",
       " 'and',\n",
       " 'would',\n",
       " 'recommend',\n",
       " 'it',\n",
       " 'to',\n",
       " 'everyone',\n",
       " 'to',\n",
       " 'watch',\n",
       " 'and',\n",
       " 'the',\n",
       " 'fly',\n",
       " 'fishing',\n",
       " 'was',\n",
       " 'amazing',\n",
       " 'really',\n",
       " 'cried',\n",
       " 'at',\n",
       " 'the',\n",
       " 'end',\n",
       " 'it',\n",
       " 'was',\n",
       " 'so',\n",
       " 'sad',\n",
       " 'and',\n",
       " 'you',\n",
       " 'know',\n",
       " 'what',\n",
       " 'they',\n",
       " 'say',\n",
       " 'if',\n",
       " 'you',\n",
       " 'cry',\n",
       " 'at',\n",
       " 'a',\n",
       " 'film',\n",
       " 'it',\n",
       " 'must',\n",
       " 'have',\n",
       " 'been',\n",
       " 'good',\n",
       " 'and',\n",
       " 'this',\n",
       " 'definitely',\n",
       " 'was',\n",
       " 'also',\n",
       " 'congratulations',\n",
       " 'to',\n",
       " 'the',\n",
       " 'two',\n",
       " 'little',\n",
       " \"boy's\",\n",
       " 'that',\n",
       " 'played',\n",
       " 'the',\n",
       " \"part's\",\n",
       " 'of',\n",
       " 'norman',\n",
       " 'and',\n",
       " 'paul',\n",
       " 'they',\n",
       " 'were',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'children',\n",
       " 'are',\n",
       " 'often',\n",
       " 'left',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'praising',\n",
       " 'list',\n",
       " 'i',\n",
       " 'think',\n",
       " 'because',\n",
       " 'the',\n",
       " 'stars',\n",
       " 'that',\n",
       " 'play',\n",
       " 'them',\n",
       " 'all',\n",
       " 'grown',\n",
       " 'up',\n",
       " 'are',\n",
       " 'such',\n",
       " 'a',\n",
       " 'big',\n",
       " 'profile',\n",
       " 'for',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'film',\n",
       " 'but',\n",
       " 'these',\n",
       " 'children',\n",
       " 'are',\n",
       " 'amazing',\n",
       " 'and',\n",
       " 'should',\n",
       " 'be',\n",
       " 'praised',\n",
       " 'for',\n",
       " 'what',\n",
       " 'they',\n",
       " 'have',\n",
       " 'done',\n",
       " \"don't\",\n",
       " 'you',\n",
       " 'think',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'story',\n",
       " 'was',\n",
       " 'so',\n",
       " 'lovely',\n",
       " 'because',\n",
       " 'it',\n",
       " 'was',\n",
       " 'true',\n",
       " 'and',\n",
       " 'was',\n",
       " \"someone's\",\n",
       " 'life',\n",
       " 'after',\n",
       " 'all',\n",
       " 'that',\n",
       " 'was',\n",
       " 'shared',\n",
       " 'with',\n",
       " 'us',\n",
       " 'all']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View an input sentence\n",
    "\n",
    "inv_imdb_word_index = {value : key for key, value in imdb_word_index.items()}\n",
    "[inv_imdb_word_index[index] for index in x_train[0] if index > index_from]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the sentiment value\n",
    "\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_2\"></a>\n",
    "## Padding and Masking Sequence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the imdb data set\n",
    "\n",
    "import tensorflow.keras.datasets.imdb as imdb\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the input data shape\n",
    "\n",
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the inputs to the maximum length using maxlen\n",
    "\n",
    "padded_x_train = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                x_train, \n",
    "                maxlen=300,\n",
    "                padding='post',\n",
    "                truncating='post'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the output data shape\n",
    "\n",
    "padded_x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Masking layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy \n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking expects to see (batch, sequence, features)\n",
    "# Create a dummy feature dimension using expand_dims\n",
    "\n",
    "padded_x_train = np.expand_dims(padded_x_train, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Masking layer \n",
    "\n",
    "tf_x_train = tf.convert_to_tensor(padded_x_train, dtype='float32')\n",
    "masking_layer = tf.keras.layers.Masking(mask_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass tf_x_train to it\n",
    "\n",
    "masked_x_train = masking_layer(tf_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=7, shape=(25000, 300, 1), dtype=float32, numpy=\n",
       "array([[[1.000e+00],\n",
       "        [1.400e+01],\n",
       "        [2.200e+01],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.940e+02],\n",
       "        [1.153e+03],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.400e+01],\n",
       "        [4.700e+01],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.100e+01],\n",
       "        [6.000e+00],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.446e+03],\n",
       "        [7.079e+03],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.700e+01],\n",
       "        [6.000e+00],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the dataset\n",
    "\n",
    "masked_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=8, shape=(25000, 300), dtype=bool, numpy=\n",
       "array([[ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       ...,\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False]])>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the ._keras_mask for the dataset\n",
    "\n",
    "masked_x_train._keras_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_3\"></a>\n",
    "## The Embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and apply an `Embedding` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding layer using layers.Embedding\n",
    "# Specify input_dim, output_dim, input_length\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=501,\n",
    "                                            output_dim=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=23, shape=(1, 4, 1, 16), dtype=float32, numpy=\n",
       "array([[[[-0.0423254 ,  0.01373792,  0.02022919,  0.03803023,\n",
       "          -0.01799964, -0.04685158,  0.01307083, -0.04625902,\n",
       "           0.00782151,  0.04451651, -0.03057462,  0.04821234,\n",
       "           0.0441776 , -0.04679091,  0.02027695, -0.02651588]],\n",
       "\n",
       "        [[-0.00642215,  0.03022708, -0.01536757,  0.00438575,\n",
       "           0.02404293,  0.01437337, -0.03687943,  0.0387536 ,\n",
       "          -0.03700986,  0.01949814,  0.02328766, -0.04982924,\n",
       "           0.00422291, -0.00267605, -0.03001887, -0.00913508]],\n",
       "\n",
       "        [[-0.04389232,  0.02962079, -0.01573833, -0.01159855,\n",
       "           0.02872647,  0.02444284, -0.02089051,  0.04959682,\n",
       "          -0.04177995,  0.00016252,  0.00169613,  0.00270583,\n",
       "           0.01488287,  0.00529456,  0.01330848,  0.04760866]],\n",
       "\n",
       "        [[-0.02696353,  0.03201881, -0.01857514,  0.01459329,\n",
       "          -0.00650484, -0.03614984,  0.03631028, -0.00640849,\n",
       "           0.04398606,  0.02314898,  0.02940444, -0.00428299,\n",
       "          -0.04567847,  0.00195171, -0.02036072,  0.00518068]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect an Embedding layer output for a fixed input\n",
    "# Expects an input of shape (batch, sequence, feature)\n",
    "\n",
    "sequence_of_indices = tf.constant([[[0],[1],[5], [500]]])\n",
    "sequence_of_embeddings = embedding_layer(sequence_of_indices)\n",
    "sequence_of_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0423254 ,  0.01373792,  0.02022919, ..., -0.04679091,\n",
       "         0.02027695, -0.02651588],\n",
       "       [-0.00642215,  0.03022708, -0.01536757, ..., -0.00267605,\n",
       "        -0.03001887, -0.00913508],\n",
       "       [-0.02609817,  0.01309371, -0.03295422, ..., -0.04412277,\n",
       "        -0.00362872, -0.02637835],\n",
       "       ...,\n",
       "       [-0.01650883,  0.03136962,  0.02102177, ...,  0.00281143,\n",
       "         0.04261489, -0.00117452],\n",
       "       [-0.04337038,  0.0113581 ,  0.03413829, ...,  0.02602358,\n",
       "        -0.02325482, -0.00333955],\n",
       "       [-0.02696353,  0.03201881, -0.01857514, ...,  0.00195171,\n",
       "        -0.02036072,  0.00518068]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the Embedding layer weights using get_weights()\n",
    "\n",
    "embedding_layer.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02249249, -0.04113618,  0.03226913, -0.00246356,  0.01929176,\n",
       "        0.037999  , -0.03747336, -0.02144735,  0.04667372, -0.00754393,\n",
       "        0.02494841,  0.03658428,  0.00441743,  0.02488853,  0.03104917,\n",
       "       -0.02327052], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the embedding for the 14th index\n",
    "\n",
    "embedding_layer.get_weights()[0][14,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and apply an `Embedding` layer that uses `mask_zero=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a layer that uses the mask_zero kwarg\n",
    "\n",
    "masking_embedding_layer = tf.keras.layers.Embedding(input_dim=501,\n",
    "                                            output_dim=16, \n",
    "                                            mask_zero=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=41, shape=(1, 4, 1), dtype=bool, numpy=\n",
       "array([[[False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]]])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply this layer to the sequence and see the _keras_mask property\n",
    "\n",
    "masked_sequence_of_embeddings = masking_embedding_layer(sequence_of_indices)\n",
    "masked_sequence_of_embeddings._keras_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_4\"></a>\n",
    "## The Embedding Projector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess the IMDb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word index\n",
    "\n",
    "imdb_word_index = get_imdb_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the keys and values of the word index\n",
    "\n",
    "inv_imdb_word_index = {value: key for key, value in imdb_word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'am',\n",
       " 'a',\n",
       " 'great',\n",
       " 'fan',\n",
       " 'of',\n",
       " 'david',\n",
       " 'lynch',\n",
       " 'and',\n",
       " 'have',\n",
       " 'everything',\n",
       " 'that',\n",
       " \"he's\",\n",
       " 'made',\n",
       " 'on',\n",
       " 'dvd',\n",
       " 'except',\n",
       " 'for',\n",
       " 'hotel',\n",
       " 'room',\n",
       " 'the',\n",
       " '2',\n",
       " 'hour',\n",
       " 'twin',\n",
       " 'peaks',\n",
       " 'movie',\n",
       " 'so',\n",
       " 'when',\n",
       " 'i',\n",
       " 'found',\n",
       " 'out',\n",
       " 'about',\n",
       " 'this',\n",
       " 'i',\n",
       " 'immediately',\n",
       " 'grabbed',\n",
       " 'it',\n",
       " 'and',\n",
       " 'and',\n",
       " 'what',\n",
       " 'is',\n",
       " 'this',\n",
       " \"it's\",\n",
       " 'a',\n",
       " 'bunch',\n",
       " 'of',\n",
       " 'drawn',\n",
       " 'black',\n",
       " 'and',\n",
       " 'white',\n",
       " 'cartoons',\n",
       " 'that',\n",
       " 'are',\n",
       " 'loud',\n",
       " 'and',\n",
       " 'foul',\n",
       " 'mouthed',\n",
       " 'and',\n",
       " 'unfunny',\n",
       " 'maybe',\n",
       " 'i',\n",
       " \"don't\",\n",
       " 'know',\n",
       " \"what's\",\n",
       " 'good',\n",
       " 'but',\n",
       " 'maybe',\n",
       " 'this',\n",
       " 'is',\n",
       " 'just',\n",
       " 'a',\n",
       " 'bunch',\n",
       " 'of',\n",
       " 'crap',\n",
       " 'that',\n",
       " 'was',\n",
       " 'on',\n",
       " 'the',\n",
       " 'public',\n",
       " 'under',\n",
       " 'the',\n",
       " 'name',\n",
       " 'of',\n",
       " 'david',\n",
       " 'lynch',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'few',\n",
       " 'bucks',\n",
       " 'too',\n",
       " 'let',\n",
       " 'me',\n",
       " 'make',\n",
       " 'it',\n",
       " 'clear',\n",
       " 'that',\n",
       " 'i',\n",
       " \"didn't\",\n",
       " 'care',\n",
       " 'about',\n",
       " 'the',\n",
       " 'foul',\n",
       " 'language',\n",
       " 'part',\n",
       " 'but',\n",
       " 'had',\n",
       " 'to',\n",
       " 'keep',\n",
       " 'the',\n",
       " 'sound',\n",
       " 'because',\n",
       " 'my',\n",
       " 'neighbors',\n",
       " 'might',\n",
       " 'have',\n",
       " 'all',\n",
       " 'in',\n",
       " 'all',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'highly',\n",
       " 'disappointing',\n",
       " 'release',\n",
       " 'and',\n",
       " 'may',\n",
       " 'well',\n",
       " 'have',\n",
       " 'just',\n",
       " 'been',\n",
       " 'left',\n",
       " 'in',\n",
       " 'the',\n",
       " 'box',\n",
       " 'set',\n",
       " 'as',\n",
       " 'a',\n",
       " 'curiosity',\n",
       " 'i',\n",
       " 'highly',\n",
       " 'recommend',\n",
       " 'you',\n",
       " \"don't\",\n",
       " 'spend',\n",
       " 'your',\n",
       " 'money',\n",
       " 'on',\n",
       " 'this',\n",
       " '2',\n",
       " 'out',\n",
       " 'of',\n",
       " '10']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first dataset example sentence\n",
    "\n",
    "[inv_imdb_word_index[index] for index in x_train[100] if index > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build an Embedding layer into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum token value\n",
    "\n",
    "max_index_value = max(imdb_word_index.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify an embedding dimension\n",
    "\n",
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model using Sequential:\n",
    "#     1. Embedding layer\n",
    "#     2. GlobalAveragePooling1D\n",
    "#     3. Dense\n",
    "\n",
    "model = tf.keras.Sequential({\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1,\n",
    "                              output_dim=embedding_dim,\n",
    "                              mask_zero=False),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API refresher: use the Model to build the same model\n",
    "\n",
    "review_sequence = tf.keras.Input((None, ))\n",
    "embedding_sequence = tf.keras.layers.Embedding(input_dim=max_index_value+1, \n",
    "                                               output_dim=embedding_dim)(review_sequence)\n",
    "average_embedding = tf.keras.layers.GlobalAveragePooling1D()(embedding_sequence)\n",
    "positive_probability = tf.keras.layers.Dense(units=1,\n",
    "                                             activation='sigmoid')(average_embedding)\n",
    "\n",
    "model = tf.keras.Model(inputs=review_sequence, outputs=positive_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, None, 16)          160016    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,033\n",
      "Trainable params: 160,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile, train, and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with a binary cross-entropy loss\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 36s 1ms/sample - loss: 0.6892 - accuracy: 0.5556 - val_loss: 0.0175 - val_accuracy: 0.5078\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 32s 1ms/sample - loss: 0.6671 - accuracy: 0.6934 - val_loss: 0.0166 - val_accuracy: 0.6797\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 31s 1ms/sample - loss: 0.6230 - accuracy: 0.7619 - val_loss: 0.0153 - val_accuracy: 0.7578\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 31s 1ms/sample - loss: 0.5728 - accuracy: 0.7926 - val_loss: 0.0141 - val_accuracy: 0.7828\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 31s 1ms/sample - loss: 0.5239 - accuracy: 0.8211 - val_loss: 0.0130 - val_accuracy: 0.7922\n"
     ]
    }
   ],
   "source": [
    "# Train the model using .fit(), savng its history\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=32, \n",
    "                    validation_data=[x_test, y_test],\n",
    "                    validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0cAAAFRCAYAAAC/qtYsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xl4VOXd//HPmTWZ7JlsQJA1ISwisgjiViDiAi5PLbZaRaS27lprW2t/tpa2+FCFuttaQbDqo1xY6tPHlVJtXVBERVbZA4JsWdiyTmbm/P6YySSTdYKZSQLv13Xlysw5Z+Z854Be8+G+7+8xTNM0BQAAAAAnOUtnFwAAAAAAXQHhCAAAAABEOAIAAAAASYQjAAAAAJBEOAIAAAAASYQjAAAAAJBEOAKAqNm0aZMMw9Cnn37artfl5ORo7ty5UaoqdmLxOaqrq2UYhl555ZV2nfd73/uepk6d+o3P/9Zbb8kwDJWUlHzj9wIAdD5bZxcAAJ3FMIxW9/fp00c7d+487vfPy8vTvn37lJGR0a7XrVu3TgkJCcd93pNdNK6f1+uV3W7XSy+9pO9973uh7RMnTtS+ffvkdrs79HwAgM5BOAJw0tq3b1/o8SeffKLLLrtMn3zyiXr37i1Jslqtzb7O4/HI4XC0+f5Wq1U5OTntriszM7Pdr0G9WF4/h8NxXH/GJ5JI/3sAgO6AaXUATlo5OTmhn/T0dEmBL9Z12+q+ZOfk5GjWrFn60Y9+pPT0dE2aNEmSNHfuXA0fPlwJCQnq2bOnrrnmGh08eDD0/o2n1dU9X7p0qS666CK5XC4NHDhQixcvblJXw2lhOTk5mj17tm699ValpqYqJydH9957r/x+f+iYiooKzZw5U8nJyUpPT9cdd9yhu+++W8OGDWv1GrT1Geqmjb377rs666yzFB8fr1NPPVXvvvtu2Pt89tlnGjt2rJxOpwoKCvTqq6+2et7S0lI5nU4tXbo0bPvOnTtlsVj073//W5L03HPPacyYMUpOTlZmZqYuvfRSbd++vdX3bnz9iouLdcUVV8jlciknJ0e//e1vm7zmjTfe0Lnnnqv09HSlpqZq4sSJ+vzzz0P7c3NzJUlXXXWVDMNQXFxc2PVpOK3ugw8+0Nlnn624uDilp6dr+vTpKi0tDe3/xS9+oWHDhmnJkiXKz89XYmKiCgsLtWvXrlY/V1s1StLRo0d12223qVevXnI6nerfv3/Ytdi3b5+mT5+urKwsxcXFqaCgQC+88EKLn8Xr9cowDL388suS6v8OL168WJMnT5bL5dJvf/tb1dbW6gc/+IH69++v+Ph4DRgwQPfff79qa2vD6nvrrbd01llnyeVyKTU1VRMmTNBXX32lN998Uw6HQwcOHAg7/umnn1ZaWpqqqqpavTYA0FEIRwAQgXnz5qlPnz5auXKl/vKXv0iSLBaLHnnkEa1fv15LlizRli1bdO2117b5Xvfcc49++MMfau3atbrkkks0ffr0Nr8Yz5s3T/3799eqVav00EMP6cEHHwwLVXfddZfefvttvfzyy1qxYoXsdrvmz5/fZi2Rfoaf/vSn+s1vfqM1a9Zo6NChmjZtmsrLyyVJx44d00UXXaQePXpo1apVmj9/vn73u9/p8OHDLZ7X7Xbr4osv1nPPPRe2/YUXXtApp5yi8847T1JgVGLWrFlavXq13nrrLdXW1urSSy+V1+tt87PVmT59ujZs2KA333xTy5cv1/r16/XGG2+EHVNRUaEf//jHWrlypT744APl5ubqwgsv1JEjRyRJq1evliT9+c9/1r59+1r889q9e7cuuOACDRw4UJ9++qn+/ve/a9WqVWFT8SRp165dWrRokRYvXqz33ntP+/fv149+9KNWP0dbNfr9fl144YVatmyZnn76aX355ZdasGBBKPiXl5frnHPO0aZNm/Tyyy9r48aNevjhh+V0OiO+lnV+/vOfa+bMmdqwYYNuuOEG+Xw+5ebmavHixfryyy81d+5cPfXUU2HB7I033tCUKVM0fvx4ffzxx1qxYoWuuuoq1dbW6oILLlCvXr20aNGisPPMnz9f11xzjeLj49tdIwAcFxMAYL7//vumJLOoqKjJvuzsbPPiiy9u8z1WrFhhSjJLSkpM0zTNL7/80pRkrlq1Kuz5k08+GXpNTU2N6XA4zEWLFoWd76GHHgp7Pm3atLBznXfeeeaMGTNM0zTNsrIy02azmS+88ELYMSNGjDCHDh3aZt2tfYY333zTlGS+/vrroWOKiopMSea///1v0zRN8/HHHzdTUlLMo0ePho5ZtWqVKSnsczT297//3bTb7WZxcXFoW35+vnnfffe1+Jq9e/eaksxPP/3UNE3TrKqqMiWZS5YsCR3T8PqtW7fOlGS+9957of2VlZVmZmamOWXKlBbPU1tba7pcLvOVV14JPZdkvvTSS2HH1V2fus/w05/+1OzXr59ZW1sbOubjjz82JZkrV640TdM077nnHtPhcJhlZWWhYxYuXGjabDbT6/W2WFNbNb722mumJHPt2rXNHv/EE0+YCQkJ5v79+5vd3/izNPe56/4OP/jgg23W98ADD5jDhg0LPR89erR5xRVXtHj87NmzzYEDB5p+v980TdP84osvWv08ABANjBwBQATOOOOMJtuWL1+u888/X71791ZSUpIKCwslqc1RoBEjRoQeOxwOZWRkNJlO1NprJKlXr16h12zZskVer1fjxo0LO6bx8+ZE+hkanr9Xr16SFDr/xo0bdeqppyopKSl0zOjRo9v81/4pU6YoOTlZL730kiRp5cqV2rJli6ZPnx465rPPPtNll12mvn37KikpSXl5ec3W15KNGzfKYrGEXYv4+HiNHDky7LitW7fq6quv1oABA5ScnKzU1FRVVVVFfJ46GzZs0Pjx42Wz1S/pPeOMMxQXF6cNGzaEtvXp00dpaWmh57169ZLX6w2bftdYWzV+9tln6tGjh0499dRmX//ZZ59p+PDhys7Obtdnak5z/z089dRTGjNmjLKyspSYmKhZs2aFajNNU6tXr9bkyZNbfM+ZM2dq165doSmVzzzzjMaOHdvi5wGAaCAcAUAEGnc/27Ztm6ZOnapBgwZp8eLF+vTTT7VkyRJJgalgrWm8eN0wjLD1Q8f7mra67zXWns/Q8Px156k7v2mazZ7bNM1Wz2+323XVVVfpr3/9qyTpr3/9q84888xQADpy5IjOP/98xcXF6bnnntOqVau0YsWKZutrSVs11Lnooot04MAB/fnPf9bHH3+sL774QikpKRGfp6GW/hwabm/uz1NSq38PIqmxrb8Dre23WAJfCRpes8Zrhuo0/u/h+eef109+8hNde+21evPNN7V69Wrdc889Ta5fa+fPycnRZZddpmeeeUZVVVV68cUX25xqCAAdjXAEAMdh5cqVqq2t1SOPPKLx48dr0KBB2r9/f6fUkp+fL5vNpo8++ihs+8cff9zq6zrqMwwdOlRr164NrUGSAqMU1dXVbb52+vTp+vTTT7V27VotXrxY1113XWjf+vXrdejQIc2ZM0fnnXeeCgoK2n0/oaFDh8rv94ddi+rq6rBGBl9//bW2b9+u++67T+eff76GDBkii8UStmbKarXKarXK5/O1eb4PP/wwbE3UJ598ourqag0dOrRdtTcUSY2jRo3S3r17tW7dumbfY9SoUVqzZk2Lo5RZWVmSpL1794a2NW740JL33ntPY8eO1R133KFRo0YpLy9PRUVFof2GYej000/X22+/3er73HjjjVq6dKmefvpp+f1+ffe7343o/ADQUQhHAHAc8vPz5ff79fDDD6uoqEh/+9vf9N///d+dUktaWpquv/563XPPPXrzzTe1efNm/exnP1NRUVGr/1LfUZ/huuuuk91u1/Tp07Vu3Tp9+OGHuummmyJa6D9mzBgNGTJE1113ncrLy8O+DPfr1092u12PPfaYduzYoWXLlulnP/tZu2obNmyYJk+erBtvvFHvvfeeNmzYoBkzZoQFt6ysLKWmpurpp5/W1q1b9eGHH+raa68NdaSTAl/u+/Tpo3feeUf79u1rcfrbnXfeqQMHDuiGG27Qhg0b9J///EfXX3+9CgsLNWbMmHbV3lAkNV544YU644wzdMUVV+i1115TUVGR3n//fS1cuFCSQl3qLrnkEr3zzjsqKirSP//5z9ANdAcPHqyePXvq17/+tTZv3qz//Oc/+vnPfx5RfYMGDdLnn3+u119/Xdu2bdPcuXP12muvhR3z61//WkuXLtXPfvYzrVu3Tps2bdKCBQvCug9OmjRJvXv31j333KOrr76a+30BiDnCEQAchzFjxuiPf/yjHn30UQ0ZMkSPP/64Hn744U6r5+GHH9b555+vK6+8UuPGjVNNTY2uvvrqsC/PjXXUZ0hKStIbb7yhPXv2aPTo0ZoxY4buvfdepaamRvT66dOn64svvtAll1wS9pqePXvqueee0z/+8Q8NGTJEv/zlL4+rvueff14FBQW68MILNXHiRA0aNEgXX3xxaL/dbteSJUu0fv16nXrqqfrhD3+oe+65p8mNXR955BF98MEH6tOnT2jdVWO5ubl6++23tXXrVo0aNUr/9V//pdGjR4daYR+vSGq0Wq16++23NWnSJN1www0qKCjQjBkzdOjQIUmBP6f3339fAwcO1LRp0zR48GDdcccdqqmpkSQ5nU4tXrxYu3bt0ogRI/TjH/9Yf/jDHyKq7/bbb9e0adN0zTXXaNSoUVq7dq3uu+++sGMuueQS/eMf/9B//vMfjRkzRuPGjdP//M//yG63h44xDEM33HCDPB4PU+oAdArDjHRCNgCgWxk/frz69eunF198sbNLASJ2xx136KOPPtKqVas6uxQAJyFb24cAALq61atXa8OGDRo7dqyqq6v17LPP6qOPPtLs2bM7uzQgIkeOHNHq1au1cOFCPfPMM51dDoCTVEzC0VNPPaXPP/9cKSkpmjdvXpP9pmlq4cKFWr16tZxOp2655Rb1798/FqUBwAnjscce06ZNmyQF1o+8/vrrmjBhQidXBUTmggsu0Nq1a3XNNdfQiAFAp4nJtLqNGzcqLi5OTz75ZLPh6PPPP9dbb72le++9V1u3btWiRYv0wAMPRLssAAAAAAiJSUOGIUOGKDExscX9n376qc4991wZhqH8/HxVVFSEFpACAAAAQCx0iW51ZWVlysjICD13u90qKyvrxIoAAAAAnGy6REOG5mb2tXRvjuXLl2v58uWSpDlz5kS1LgAAAAAnjy4Rjtxud9hdz0tLS5WWltbssYWFhSosLAw9b3gn786WkZHR7ru3I3Jc3+jjGkcf1zj6uMbRxzWOLq5v9HGNo68rXeOePXtGfGyXmFY3evRovffeezJNU1u2bJHL5WoxHAEAAABANMRk5OiRRx7Rxo0bdezYMd1000268sor5fV6JUmTJ0/W6aefrs8//1x33HGHHA6HbrnllliUBQAAAAAhMQlHP/7xj1vdbxiGbrjhhliUAgAAAADN6hLT6gAAAACgsxGOAAAAAECEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmSrbMLAAAAAND9mV6v5KmWuXm9jh3YIzNvmIwBBZ1dVrsQjgAAAICTRF2AUU2NVFPd4HGVVFMjM2xb3ePAj1lT0+B5TWh76HifN3SeSkmyO2S5+/fdKiARjgAAAIAuxPT5GgWX6rAgYjYMLtXhx5mNwk6ToOP1tl1AQ3aH5HRKjjjJ2eAnJU2GM65+X1yc5IiTuWOztO4zSabk88rcvI5wBAAAAJzITL+v2eASFlKqmxuFqZHZUnCpPs4AY7OHBxeHsz7AOJyh4KKGYSb42HDGN9lWH3acMizW9l2X7Zvk37Q2MIpktckYdGr7Pksni1k4+uKLL7Rw4UL5/X5NmjRJl19+edj+yspKPfbYYyotLZXP59Mll1yiCRMmxKo8AAAAnGDCAkyDIFKzxynz4IEGoyzNj9KYnoZTxxqMxtRUS97a9hVjs0nNBZGkFBkZ2c0Gl7rjjWaDS30QMqztCzDRZAwokOXu38u1Z4cqc/t3q1EjKUbhyO/3a8GCBbrvvvvkdrt17733avTo0crNzQ0d89Zbbyk3N1e/+MUvdPToUd15550655xzZLMxuAUAAHCiMv3+lkdQmlsD02iUxqwLLtVVwQDT4PhaT7PnPNxSMTZb8yMoSSlNQ0qjoGM0F1wa7u9CASbajAEFShh7tqpKSjq7lHaLSfLYtm2bcnJylJ2dLUkaP368Vq1aFRaODMNQdXW1TNNUdXW1EhMTZbHQaRwAAKCzBQJMTZPF+03WwDQzvUyeGpkNg0toFCb4uIUA0yKrrZkRFKeUlCw5giGlhaliRnDaWUpWto5UVzfdzz/Kn/Ri8jegrKxMbrc79Nztdmvr1q1hx1x44YV68MEHdeONN6qqqkp33XVXs+Fo+fLlWr58uSRpzpw5ysjIiG7x7WCz2bpUPScarm/0cY2jj2scfVzj6OMaR49n0zpVvf+WkgefJkdB+9Zq1AUYf3WVzOoqmTXV4b9b215TJbO6ue3V9cGmPaxWGXEuGXFxMpzx9b/T0oPP45vui4tr/jWNt3dAgLHZbHK0d10PIrZ+31G99dnXGtEzScN6JHd2Oe0Sk3BkmmaTbYZhhD1fs2aN+vTpo1//+tc6cOCAfve736mgoEAulyvsuMLCQhUWFoael3Sh4bqMjIwuVc+JhusbfVzj6OMaRx/XOPq4xt9MoBNZVWDqWE11cBSmWmbRNpmvPi/5fZLFIp1VKCMhKWyUJWwNTONRmOMIMKFRl7rfdQv6k1KCU8icgdGWRqM0oW0tjNIYNnv4Zw7+HP9Fk1RVE/jpAPwdbp7fNOU3JZ8/+Ns05W/w2OcPHONrZl/d64oOVevZz4vl95uyWQ39btIpKsiM79TP1bNnz4iPjUk4crvdKi0tDT0vLS1VWlpa2DHvvvuuLr/8chmGoZycHGVlZWnv3r0aOHBgLEoEAAAIY5pmoGtYMLwEwkxVKNCYDcNN46ATdmx1YD1Me6aR+XzSe2/LtFiCi+4bhZf4BCk1vdngUnd82PSyxu/hiJNstib/WH2yME1TPr8Z9qXeZwa/+Ae/8PuDYSD8mOC+hseHwkRwWzPv1TBYNA4fze9r+L51QaSulvDzhNfU3Oepe+9Gn6eZfd8owDbD6ze1/kBlp4ej9ohJOBowYID27dungwcPKj09XStWrNAdd9wRdkxGRobWrVunwYMH6/Dhw9q7d6+ysrJiUR4AAOjmTNOUPJ6w8NIwsJiNwkvDoGM2Di/VVfXH+XyRF+FwBMNIMMDExQd+UtJkxMXX74uLCzsusC9OZvEBbfq/17U+ua+GHdulgpk/kJE/9BsFGLPui3Poi3zwS7bPlM/rC30Rb/KF3d/o+Ba+1DfcF/7lO/yLeItf3IP76s/b8hf3ZgNDa/taGPGo+7xdicWQrIYR+G0xZDUki2HI0uCx1RJ+jMUI32ezGHIYRmhf4/eyWoK/w94j8J4NH1tCxzV/TOPzBt6v/v33HK3Ros+L5TNN2SyGhmW72r4AXUhMwpHVatXMmTM1e/Zs+f1+TZgwQb1799ayZcskSZMnT9YVV1yhp556Snfffbck6fvf/76Sk7vXHEUAANC2UHeyFkZezCajNPXhxWwYXBoHnmam8TfLMILBpGFYiZMSk2W4s5qEF8XFh4436o5tFHT8Doe8pkU1Xr9qfKZqfH55vGb98+Bvj8+vmtB2vzw+UzUev2qqTBV7UrXutN7yy5QhQ323OxS366uwMNF49CCSMNCV1H25rv/C3eDLdtgX+abHNDzObkhWwxIWFJoLA3VBIPDe9e+ZlOhSdVVVKAyEB5Pw8NAkmLQYJsI/T/jrW/jMwfc8kUbwRvRI0MD0eO0ol/onqluNGkmSYTa3IKgb2bt3b2eXEML81eji+kYf1zj6uMbRxzXuWM2tj0mJc+rIgQPBG1k2CjfB8NJawGnX2hiLJRhOmoYVIyy4BANLXF1b5cB2vzNOHnucamzOwI/VIY9hk8ev+tDiDYaUuuAS/O1p9DwUeMKe14We4/s65bAacloNOawWeXx+HfP4Q/uyE2zKTnI0O6IQ8b/wNzwmLAg0FyYajli0HhiaG8EIDwzNh5SuEgL4/0T0daVr3OXWHAEAgOiKaH1MdZWam1pmNrcupi7wNHOjy0MtFWGzNz/qkpQSbKFcH158jnh5HPGqccTLY4+Xpy682JzyWO2qsQR/TCMYXMz6ENNgNKZhgPH4TNUc86vmUH2AqfWbkjzBn2MRX0+H1ZDTZgkFF6fNkDP4OznOHgw14dvDjwu+Nvjb2eC3o8FvS4OwsKm4Sr/611fy+gPTkX5yVq9u96/uQHdHOAIAIMaaXx9TP/piNhtwAuGlxSDT7vUxzkZTxgKL/H1pGfI4E+RxulTjcKnGEa8ae7xq7HHy2JzyWJ2yJqXoUE2taix2eQybagyrakyrPKaaDTBh08l8ftVUmPIea2mkpSb405Sh8NDitNWHknibRalxFjmtFjlsRoNAUve8mQBTF1IaBRp7o9ASKwWZ8frdpFO67XQk4ERAOAIAoBWm31d/08vWOpI1M+piNhmlOf71MV5ngmriE1UTnyiPM0E1qZnyOOKDISZeNba4+tEXqyM0+hIILzbVyKoaWQIjMaYRCCx1YcVnBqeH+eX1Nzh33YBLE56wAwypQWCpCyCB5y6HVWktjJw4mxudCQaapiMxhuwWo8tMy4qWgsx4nT2460xHAk42hCMAwAnDv3WDypdtlj+zh4yc3PCOZM1NGYugAUBr62NMSV7DGgwiDtXY41QTlyBPXKJqnAmqcabI48pRTapLHruzPsBYHYEAY7EHgovFJk8wvHhkUY3fUI1pqMan0KhLq0ta/Go2yFgMNQgaktNmBgOJlOSwyuFqPDWsLrg0mhoWFlwM5WS6VXH0cOi1tpMgtAA4ORCOAABdnmmaUlWFdKhMOlwq83CpdDj4+FDwcckBbbamaX3qAA09/I76l+8NhA+LPRBGLHZ5rPbANqsjMFUsOHXM40hWjSNOnoS4BiMvwddY7KqxBEZePLIER18CAcbjD+SSdvFLVlNyyiKngoHDUj8VLNlmCRsxaTglzGltMOrS+HlouyW0HsZmic4C+IzUeJV4Kzr8fQGgsxGOAACdyvTWSkcONQo7pdKhsrAQVDeCU2GNU3Fcqkri0lScnKPipP4q7jlGX/VM0m5HgxuMH0cosFmMZhfRO2wWpTY3NazRVLAmoy51U8MarY+xWRhlAYCuiHAEAIgK0zSlynIpGHZCIzyHS2XWBZ5DpdKxI6HX+GXosCNJxQluFaf1VnHyEBVnulXiSFGxxaVi06FKvyXsPDaLocwEm0xPrVRtBkKR6deIFEOjB2Y1DTJ1ozF1QafB6IyV0AIAJzXCEQCg3cza2kC4OdxodOdQwylvZVJt+CIYj8WmkvRcFaflqiRrlIr7ulXsSFGxNUHFpkOltRZ5G62tSXBYlJVgV3aCXcNcNmUm2JWVYFdG8HdKnFUWwwi0QV6+K9AG2WrRVWP70O0LANAuEYWj5557Tuedd5769u0b5XIAAJ3JNE2p/GhgROdIWf0Ut8Phj1V+tOlr7Q6Vu3sGws/AoSp2ZajEmaKDlgSVmA4V11p02BOefAxJ6fZA4BmUYFdGgk1ZCXZlhn5sctmtEdVekBmv3xX2oQ0yAOC4RRSOfD6fZs+ereTkZJ1zzjk655xz5Ha7o10bAKADmZ6apk0MGo7+BAORvN7wFxqGlJQiX2qGDmX0UUn/sYFpb85UlVgTdNB0qqTWooNVPlU3HPbxSY4aIxByXDb1bRB6soLBx+2yd+j6G9ogAwC+iYjC0cyZMzVjxgytXr1a77//vpYuXaq8vDyde+65Gjt2rOLi4qJdJwCgBabfL5Ufqe/kVhdyGk5xO1QaWP/TmDNOSnVLqenyDByq4uQeKknMVLEzNTTVrbjWouJKr0oqvfLXZZ+qwE+S06qsBJt6pNh1Ws/60Z66EJTitNLiGQDQbUS85shisWjUqFEaNWqUdu/erccee0xPPfWU5s+fr7POOktXXnml0tPTo1krAJx0zJrq+oYGDUd6Gk5xO3JI8jUe7bFIyalSarqUmSPlDdWx5EwVJ2SqOC5FxdZEFZtOFXuk4gqviitqdbTGJ9VKOhR4C4shueP9ykywanCmKxR86qa9ZbjsirdbmtQMAEB3FXE4qqys1Mcff6z3339fu3bt0tixY/WDH/xAGRkZeu211/TAAw9o7ty50awVAE4Ypt8nHT0SDDilMg81aGgQHPXR4bLAvX0ai4sPjPakuWUMGialpsuX4lZZcMTnoC1RJX6Hiqu8oeBTXFGrmqOmFFoqVCun1Rua4jYwPS5sxCcrwa70eBvd2wAAJ5WIwtG8efO0Zs0aDR48WOeff77GjBkju90e2j99+nTNmDEjWjUCQLdiVle2OMWttPyofMUHpKOHJH+j24daLFJKemC0J6eXjILhUppbSnWrOildJXFpOmhLULHHopJKrw5W1KqkolYHK2pVdsAr/35JMiUdkySlOK3KTLCrd4pTI3smNGp0YFeSw8KUNwAAGogoHOXl5ekHP/iBUlNTm91vsVj0zDPPdGhhANDVmD5f8GalDVtYN7xZaXC0p7qq6YvjE6TUdFmycmQMGRFa52OkpctMSdcRV7qKLfEqrvIFR3oCIz4HK2pVsqdWxzx+SZXBH8n6w0ghAAAgAElEQVRqSG6XXVkJNp2a7Qob8clIsCnTZZfTxpQ3AADaI6JwNHz4cHkbdS8qKSlReXl5qL230+ns8OIAIBZM0wxMXwt1citrMN2twT17jh6WzEajPVZrYLQnzS316iNj6MjAyE+qW0Zw1Kc2OU1lXquKK2tVZcRpx4FDoaluxV8FglCtP7y7WpzNoqzgNLeCjPjQPX3qpr6lxTHlDQCAjhZROHr88cf185//PGyb1+vVE088wTojAF2a6fU2GO0Jb2Ft1nVxO1wqeWqavjghKRh00mXk9g1NcTOCoz5KS5cSU1TlM3WwPDjaU1kbCj4Hd3pVXFGpQ1VH1ei+pkqLC0x565cWpzNy60NPVoJdmS67EpjyBgBAzEUUjkpKSpSdnR22LScnR8XFxVEpCgDaYppmoDV1405ujae4HTsimY2iic0WGu0xTukvDR8TCDop6aHRHqWmy3A45TdNHa4OTHU7WF5bH36KvCpef1jFFcWqqA0fTbJZDGW4Al3dRvRICI0AZSbYNSg3S5aaY3JYmfIGAEBXE1E4Sk9P144dO9S/f//Qth07digtLS1qhQE4eZm1tYEmBo2muDXp5FbrafrixOT6Tm59BjaZ4qZUt5SYFBqVqfX5Q80NQiM+270qqTgQWO9T6ZXXHx6uEuyWUNgZkhUfvMmpXVmJgW2pcVZZWhj1yUiNV0lJMx3oAABAp4soHE2ZMkUPPfSQLr30UmVnZ+vAgQP6v//7P33729+Odn0ATiCmaUrlxxpNcatrbtBgilv50aYvtjvqp7j1zQtNcQsEn/Rglze3jAadNE3TVIXHr+LK2vrwU1yt4opjoU5vh6p9YacxJKXFB0Z68txxGn9Kg0YHrsD2BIc1uhcKAAB0iojCUWFhoRISEvTOO++otLRUbrdb06dP17hx46JdH4BuwvTUNGhoUNe+um5tT2DUR0fKpEbNXSRJSSmBsJOeIaP/oKZT3NLckiuxyRocn9/UoWqvioPrfQ4ePBpqbV3X8a3KGz7lzW4xQut7RvVKrF/nE+zw5nbZZbey1gcAgJNRxDeBPfPMM3XmmWdGsxYAncjcvkkV/9khM7e/jAEF9dv9fqn8SCD4NFzPE7xvT6iTW8Wxpm/qcNZPcRs4uPkpbimpMmz2pq+VVOMNjPoUH/WqeN+R+g5vFbU6WOFVaWWtfI2WEyU5LMpIsKtHkkPDcxKaNDpIibPS6AAAADQr4nB0+PBhbdu2TceOHQtMjQmaOHFiVAoDEDv+dZ/JfGq2yr0+yWJIeUMlb21wtOeQ5Gs02mMYUnJaIOxkZMvIG9Joips7MPoTn9BiEDFNU8c8fhUfrdXBiuomIz7FFbU6UhM+5c1iSOnBKW8FmfHKSkgONT7ITAxMe3PZmfIGAACOT0Th6JNPPtHjjz+uHj16aPfu3erdu7d2796tgoICwhHQzZg1NdLu7TKLtkpFW2Tu3CoV768/wG9KX++ScvvKyB8WCDmpbhnBUZ/AaE+aDGvrIcTnN1XWqNFBcUX985LKWlV7w4d9HFYjOMXNrv7pzvpGB8Ft6S6bbNzbBwAARElE4Wjx4sW65ZZbdOaZZ+r666/Xgw8+qHfffVe7d++Odn0AvgHT75P27pZZtEXauTXw++tdkj+4Dic9Q+qbLw09XfpgueT3SVabLLfdFza1rjnVXn+oqcHBBqM9dT+lVV41avKmZGfg3j69Uxw6vWdCaKpbYNqbTUlOprwBAIDOE/F9jhqvNzrvvPP0ox/9SNOnT49KYQDaxzRNqaw4MBpUtFXmzi3Sru1STXXgAFeC1DdPxoXfkdEvL/A4NT30+i+HTtDm3WUa1DtdBf0H6XC1N2zEp7jhtLdKr441M+Wtrpvb0GxXqLV1aNpbgl1OG/f2AQAAXVdE4Sg5OVmHDx9WamqqMjMztWXLFiUlJcnv97f9YgBRYVYck4IhqG6KnI4dCey02aTe/WWcVSj1y5PRN1/K6iHD0jSceHx+Ldt2WM9ulHxmurRBsn25WY2avCnOZoQaG+RnxAdHfALBJyPBrvR4m6xMeQMAAN1YROFo0qRJ2rRpk8aNG6cpU6Zo1qxZMgxDU6dOjXZ9ACSZtR7pqx2B9UFFWwLT4w7uqz+gR28Zw0ZJ/fIDo0K5fVvsAOfzm9pxqFpr9ldq7f4KfVlcJU+jlm/57niNPyUpNOKTmWBXosPClDcAAHBCiygcXXrppbIE/8X5vPPO09ChQ1VdXa3c3NyoFgecjEy/T9r/dWA0qG5UaE+R5AtOY0t1B0aDzj5fRt88qc9AGa6Elt/PNPX1MY/W7q/Umv0VWnegUhWewLBQnxSnLhiYKne8Tf+zrkRevymbxdB1p2epIDM+Bp8WAACg62gzHPn9fl177bVatGiR7ME7z2dkZES9MOBkYJpmoF12MASZRVukXduk6qrAAfGuwNqgyf8lo19+4HGau833La2s1dr9lVp7oEJr9leqtDLQijvTZdOZvZM0PNul4TkJSouv/1/A4CyXdpRL/RNFMAIAACelNsORxWJRz549dezYMaWnp7d1OIBWmJXl0s5tMutaaBdtlY6UBXZabYHpcOMmBKfH5UvZPZtdJ9RYhcen9QcCI0Nr9ldqz1GPpMANUU/NSdBpOS6dlpOgnER7i1PjCjLjdfbgDJWUlHTY5wUAAOhOIppWd/bZZ+sPf/iDLrroIrnd7rAvV8OGDYtacUB3ZtbWSnuKAqNBdd3j9n9df0B2LxmDh0t9g+uEeveTYXdE9N4en1+biqu0JjhVbntZtfym5LQaGpLl0qQBKRqRk6C+aU5ZWCcEAAAQkYjC0bJlyyRJS5YsCdtuGIaeeOKJjq8K6GZMv186sDd4P6HgOqHdRZIvMJ1NyamB0aBxEwJBqE+ejITEiN+/pSYKFiPQPOE7Q906LSdBgzLiZLfSLhsAAOB4RBSOnnzyyWjXAXQr5uGy8HVCO7dKVZWBnc54qe9AGYWXBqbG9cuT0jLa1emtzSYKeak6LTtBQ7Pj5bJbo/ERAQAATjoRhSPgZGZWVUq7ttXfWLVoq3QouC7HapV69ZVxxrmBkaG++VKPXjIs7Q8sYU0U9lWqtKrtJgoAAADoOBF9y7r55ptb3PenP/2pw4oBOpvprZW+3lW/Tqhoi7R/j2QG7wOU1UNG3tBAK+1++YF1Qg7ncZ2r3OPThuaaKDitwSDUdhMFAAAAdJyIwtHtt98e9vzQoUN64403dNZZZ0WlKCAWTNOUDu4LTYszi7ZIX+2QvLWBA5JSAqNBZ5wjo29+YKpcYvJxn6+tJgqFA1J0Gk0UAAAAOk1E4WjIkCFNtg0dOlSzZ8/WxRdf3OFFAdFgHj0UGg0K3GB1q1RZHtjpcEp9BsiYOKW+e5w76xuN2ETSRGFEToLyaaIAAADQJRz34gWbzaaDBw92ZC1AhzGrq6Rd22Xu3BKaIqey4sBOi0Xq2UfGqPHB+wnlST1OkWH9Zo0N6poorNkXWDdEEwUAAIDuJaJwtHjx4rDnNTU1Wr16tU4//fSoFAW0h+n1Snu/CjVLMIu2SHt3S2YgmCgjW8aAAmnSJYF1Qqf0l+GM65Bz1zVRWLO/Qmv31zdRyEoINFE4LSdBw7NdSqWJAgAAQJcX0Te20tLSsOdOp1NTp07VueeeG5WigJaYpimVHAi/sepX2yVPoJmBEpMC0+JGnhkIQn3zZCSldNj5yz0+rT8QmCZHEwUAAIATS0Th6JZbbol2HUCzzGNHQs0SDn29S/4t66XyY4GddkdgndC5F9V3j8vI7tBQ0loThaE0UQAAADihRBSOXn31VQ0bNkwDBw4Mbdu2bZs2bNigyy67LGrF4eRi1tRIX20P7x5XciCw07DIf0o/GSPGBYJQ33yp5ykybB07Xa1hE4U1+yu0qcUmCvGyWwlDAAAAJ5KIvlm+8cYbuvDCC8O25ebm6qGHHiIc4biYPp+076tA17i67nF7d0n+4Dohd5aMvnnSty4ONEw4ZYDcub1VUlLSsXW01kQhlSYKAAAAJ5OIwpHX65Wt0b/Q22w2eerWeQCtME1TKj0YbJ8d7B63a7vkqQkc4EoIrBM6bUz9OqGUtKjVQxMFAAAANCeib3/9+/fX22+/rSlTpoS2LVu2TP3794/4RF988YUWLlwov9+vSZMm6fLLL29yzIYNG7Ro0SL5fD4lJSVp1qxZEb8/ug6z/GhwWtzW0BQ5HTsS2GmzB7rFnTM5EIL65UtZPaLavKCtJgqn5SRoeI6LJgoAAAAnuYjC0XXXXaff//73eu+995Sdna0DBw7o8OHD+tWvfhXRSfx+vxYsWKD77rtPbrdb9957r0aPHq3c3NzQMRUVFZo/f77+3//7f8rIyNCRI0eO7xMhpkxPjbS7SGbR5vo22sX7AzsNQ8rJlXHq6PqGCb36yLDZo1oTTRQAAABwPCIKR71799ajjz6qzz77TKWlpRo7dqxGjRqluLjI7hWzbds25eTkKDs7W5I0fvx4rVq1KiwcffDBBxo7dqwyMjIkSSkpHdd+GR3D9PukfV8H7ycUXCf09U7J5wsckJYRCEHnXBBYJ9RnoIx4V9TraquJwrRhbp2WTRMFAAAAtC6icFRWViaHw6GzzjortK28vFxlZWVKT0+P6PVutzv03O12a+vWrWHH7Nu3T16vV7/5zW9UVVWliy++WOedd16knwMdzDRN6VBJaDTI3LlV2rlNqqkKHBDvCkyLu+DbgSDUN09Gqrv1N+3A2tpqojAiJ0FDsmiiAAAAgMhFFI4eeugh3XzzzUpMTAxtKysr05///Gc98MADbb7eNM0m2xqv7fD5fCoqKtKvfvUreTwe3XfffcrLy1PPnj3Djlu+fLmWL18uSZozZ05opKkrsNlsXaqe9vCXH1Xttk2q3bpR3q0bVbvtS/kPBW/+a7PL1i9P9klTZM8bLHveEFl79JZhscSsvuLyGi3bUqKVO8v02e7DKi4PrBvKSXJqQl6mRvdO1ajcFKUnOGJW04moO/8d7i64xtHHNY4+rnF0cX2jj2scfd31GkcUjvbu3atTTjklbNspp5yir7/+OqKTuN1ulZaWhp6XlpYqLS2tyTFJSUmKi4tTXFycBg8erF27djUJR4WFhSosLAw97+jWzt9ERkZGl6qnJWatJ7hOqK573FbpQIM/y5xeMgYNl1G3Tii3n0y7XR5Jof6EZWVRrbGtJgrThqQ3aaLgrzqqkqqolnXC6y5/h7szrnH0cY2jj2scXVzf6OMaR19XusaN80RrIgpHycnJ2r9/v3JyckLb9u/fr6SkpIhOMmDAAO3bt08HDx5Uenq6VqxYoTvuuCPsmNGjR+vZZ5+Vz+eT1+vVtm3bwrrj4fiYfr904OtAo4S6hgl7dkq+QPtqpaRJ/fJlnDkh2EZ7oAxXYqvvGQ0en19fFleFWmw310ThvMG9lKoqmigAAAAgKiIKRxMmTNC8efP0ve99T9nZ2dq/f78WL16siRMnRnQSq9WqmTNnavbs2fL7/ZowYYJ69+6tZcuWSZImT56s3NxcjRgxQj/96U9lsVg0ceLEJqNVaJt5uFTasUVm3YjQrm1SVWVgpzM+EH7Ovyy4TihfSnN3SvvqUBOFfZVacyC8icKgjOabKGRkJKqkpDrmtQIAAODkEFE4uvzyy2Wz2fT888+rtLRUbrdbEydO1NSpUyM+0ciRIzVy5MiwbZMnTw57fumll+rSSy+N+D1PdmZlhbRrm8ydW0MjQzocnL5otUq5/WSMPS9wg9V+eYHpcpbOaVBgmqa+PurRmv3NN1G4MC9Vp9FEAQAAAJ0oonBksVgILp3M9NZKe3YGRoPqusft3yPVNbvI6ilj0LDAFLm+eYEbrdo7tzlBaWVtIAztr9Da/ZUqrQpM5ctKsOnM3kmBm69mu5QaH9FfQwAAACCqIv5W6vV6tXfvXh09ejRs+7Bhwzq8qJOd6fdLB/cF7ycUHBXavUPyBtcJJaVI/QfJOOPc+nVCCZGt/4qmuiYKa4JhqHEThdNyEpo0UQAAAAC6iojC0aZNm/THP/5RtbW1qqqqUnx8vKqrq+V2u/XEE09Eu8YTnnnkUOimqubOLdLOrVJlRWCnwxkIPxMvCUyN65cvpWd2iXDRVhOF8wemaHh2gvqmOWmiAAAAgC4vonD03HPP6dJLL9XUqVN1/fXXa+HChXrllVfkcHBPmfYyqyulXdsDN1YNttJWWbDNocUi9eojY/TZgZuq9suXevSWYe0aa3AaN1H48mCVav2mrIaUX9dEISdB+e76JgoAAABAdxHxfY4uvvjisG2XX365br31VtYhtcL0eqW9u2Tu2FJ/P6F9u+vXCWXmyBgwWCoMNkzoPUCG09m5RTfQsInCmv0VWn8wvInCRfk0UQAAAMCJI6Jw5HK5VFVVpYSEBKWmpmrPnj1KTExUdTVtlev4t32pY//3hXymZFRVBNYJfbVDqg3eNjUxOdAsYdRZwXVCeTKSkju36GY0bKKwZn+lykJNFOz1TRRyXEqNo4kCAAAATiwRfcMdO3asVq9erbPPPlsTJ07UrFmzZLVadeaZZ0a7vm7Bv+5TmY/9VsG7Ccm02QLts791UX33uIzsLrFOqLHyGp/WHazvKFfXRCHZadWpwSYKp+W4lJPEFEoAAACc2CIKRzNmzAg9vuSSS5SXl6eqqiqddtpp0aqre9ldVP/YsMiY+j1ZplzZefW0orUmCsOyaaIAAACAk9dxzY0qKCjo6Dq6NWPQqTLtDsnnlaw2GQXDO7ukkLaaKFw5zK3hNFEAAAAAji8cIZwxoECWu38v154dqsztL2NA54XH1poo9KWJAgAAANAiwlEHMQYUKGHs2aoqKYn5uVtrojC+d5KG00QBAAAAaBPflruhtpoojOiRoOHZNFEAAAAA2qPd4cjv94c9t1gsHVYMmhdJE4XTchLUJ5UmCgAAAMDxiigc7dixQwsWLNBXX30lj8cTtm/x4sVRKexk5vOb2l5WHQhDNFEAAAAAYiKicPTkk09q1KhRuvnmm+V0OqNd00mHJgoAAABA54soHJWUlOiqq67qkjcx7a7qmiisCa4bookCAAAA0Lki+uY9ZswYrVmzRiNGjIh2PSeshk0U1uyv1NcNmigMz3HptByaKAAAAACdKaJwVFtbq7lz56qgoECpqalh+2677baoFNbd1Xj92lRSpTX7KrT2QGWoiUKczdDQLJcm00QBAAAA6FIiCke5ubnKzc2Ndi3d2saDlfpk7TZVVVVr7zGPviyub6IwiCYKAAAAQJcXUTiaNm1atOvo1j7dc0y/+8/Xoec5iXZdnJ+q4TRRAAAAALqNiFf7r1+/Xu+9954OHTqktLQ0nXvuuRo2bFg0a+s2ig7XhB5bJJ0/IFXfGebuvIIAAAAAtFtEd3D917/+pUceeUSpqak644wzlJaWpkcffVTLly+Pdn3dwqnZCXJYDVkMyRa8MSsAAACA7iWikaN//OMfuu+++9S3b9/QtvHjx2vevHkqLCyMVm3dRkFmvH436RTtKJf6JwaeAwAAAOheIgpHx44da9KQoWfPniovL49KUd1RQWa8zh6coZKSks4uBQAAAMBxiGhaXUFBgf7617+qpiawtqa6ulrPP/+88vPzo1ocAAAAAMRKRCNHP/zhD/XII49oxowZSkxMVHl5ufLz83XnnXdGuz4AAAAAiImIwlFaWppmzZqlkpISHT58WGlpaXK76cYGAAAA4MTRYjgyTVOGEbhZqd/vlySlp6crPT09bJvFEtHMPAAAAADo0loMRzNmzNBzzz0nSbrqqqtafIPFixd3fFUAAAAAEGMthqN58+aFHj/xxBMxKQYAAAAAOkuLc+IyMjJCjz/66CNlZmY2+Vm5cmVMigQAAACAaItowdDf/va3dm0HAAAAgO6m1W5169evlxRovlD3uM6BAwcUHx8fvcoAAAAAIIZaDUd/+tOfJEkejyf0WJIMw1BqaqpmzpwZ3eoAAAAAIEZaDUdPPvmkpEBDhttuuy0mBQEAAABAZ4hozRHBCAAAAMCJrtWRozqVlZVasmSJNm7cqGPHjsk0zdC+htPtAAAAAKC7imjkaP78+SoqKtJ3vvMdlZeXa+bMmcrIyNCUKVOiXR8AAAAAxERE4Wjt2rW6++67NWbMGFksFo0ZM0Z33XWX3n///WjXBwAAAAAxEVE4Mk1TLpdLkhQXF6eKigqlpqZq//79US0OAAAAAGIlojVHffr00caNG3XqqaeqoKBACxYsUFxcnHr06BHt+gAAAAAgJiIaObrxxhuVmZkpSZo5c6YcDocqKiroYgcAAADghBHRyFF2dnbocXJysm666aaoFQQAAAAAnSGikaNnn31WmzdvDtu2efNmLVq0KBo1AQAAAEDMRRSOPvzwQw0YMCBsW//+/fXBBx9EpSgAAAAAiLWIwpFhGPL7/WHb/H5/2M1g2/LFF1/ozjvv1O23365XX321xeO2bdum7373u/r4448jfm8AAAAA+KYiCkcFBQV6+eWXQwHJ7/dryZIlKigoiOgkfr9fCxYs0C9/+Us9/PDD+vDDD7Vnz55mj3vxxRc1YsSIdnwEAAAAAPjmImrIcP3112vOnDm68cYblZGRoZKSEqWlpemee+6J6CTbtm1TTk5OqLHD+PHjtWrVKuXm5oYd9+abb2rs2LHavn17Oz8GAAAAAHwzEYUjt9utP/zhD9q2bZtKS0vldrs1cOBAWSwRDTyprKxMbrc77P22bt3a5JhPPvlE999/v/70pz+14yMAAAAAwDcXUTiSJIvFovz8/OM6SXNrkwzDCHu+aNEiff/7328zcC1fvlzLly+XJM2ZM0cZGRnHVVM02Gy2LlXPiYbrG31c4+jjGkcf1zj6uMbRxfWNPq5x9HXXa9xiOLrrrrv08MMPS5JuvvnmFt8gklEet9ut0tLS0PPS0lKlpaWFHbN9+3Y9+uijkqSjR49q9erVslgsOuOMM8KOKywsVGFhYeh5SUlJm+ePlboph4gOrm/0cY2jj2scfVzj6OMaRxfXN/q4xtHXla5xz549Iz62xXB04403hh7ffvvt36igAQMGaN++fTp48KDS09O1YsUK3XHHHWHHPPnkk2GPR40a1SQYAQAAAEC0tBiOnn/+ec2ePVuStGHDBk2bNu24T2K1WjVz5kzNnj1bfr9fEyZMUO/evbVs2TJJ0uTJk4/7vQEAAACgI7QYjvbu3SuPxyOHw6HXXnvtG4UjSRo5cqRGjhwZtq2lUHTrrbd+o3MBAAAAQHu1GI7GjBmjO++8U1lZWfJ4PLr//vubPW7WrFlRKw4AAAAAYqXFcHTLLbdo06ZNOnjwoLZt26YJEybEsi4AAAAAiKlWW3kXFBSooKBAXq9X3/rWt2JUEgAAAADEXovhaOPGjRoyZIgkKSsrS+vXr2/2uGHDhkWnMgAAAACIoRbD0YIFCzRv3jxJLd/LyDAMPfHEE9GpDAAAAABiqMVwVBeMpPB7EAEAAADAichyPC9av369vvzyy46uBQAAAAA6TUTh6P7779emTZskSa+++qoeffRRPfLII1q6dGlUiwMAAACAWIkoHO3evVv5+fmSpH/961+6//77NXv2bP3zn/+ManEAAAAAECuttvKuY5qmJGn//v2SpNzcXElSRUVFlMoCAAAAgNiKKBwNGjRIzz77rA4dOqQxY8ZICgSlpKSkqBYHAAAAALES0bS6W2+9VS6XS3369NGVV14pSdq7d68uvvjiqBYHAAAAALES0chRUlKSrr766rBtI0eOjEpBAAAAANAZIho5eu2117Rz505J0pYtW3TzzTfrtttu05YtW6JZGwAAAADETETh6PXXX1dWVpYk6aWXXtLUqVP17W9/W4sWLYpmbQAAAAAQMxGFo8rKSrlcLlVVVWnnzp266KKLNHHiRO3duzfa9QEAAABATES05sjtdmvz5s3avXu3Bg8eLIvFosrKSlksEWUrAAAAAOjyIgpH11xzjf74xz/KZrPp7rvvliR9/vnnGjhwYFSLAwAAAIBYiSgcjRw5Uk8//XTYtnHjxmncuHFRKQoAAAAAYi2icFSnqqpKx44dk2maoW3Z2dkdXhQAAAAAxFpE4WjPnj167LHHtGvXrib7Fi9e3OFFAQAAAECsRdRRYf78+Ro6dKieffZZuVwuLVy4UOeff75uvfXWaNcHAAAAADERUTjatWuXvv/97yshIUGmacrlcumaa65h1AgAAADACSOicGS32+Xz+SRJSUlJKikpkWmaKi8vj2pxAAAAABArEa05Kigo0EcffaRvfetbGjdunB544AHZ7XYNHTo02vUBAAAAQExEFI5+8pOfhB5fddVV6t27t6qrq3XuuedGrTAAAAAAiKV2tfKWJIvFQigCAAAAcMJpMRw9/vjjMgyjzTe47bbbOrQgAAAAAOgMLYajnJycWNYBAAAAAJ2qxXA0bdq0WNYBAAAAAJ2q1Vbemzdv1gsvvNDsvhdffFFbtmyJSlEAAAAAEGuthqOlS5dqyJAhze4bMmSIli5dGpWiAAAAACDWWg1HO3fu1IgRI5rdN3z4cBUVFUWlKAAAAACItVbDUVVVlbxeb7P7fD6fqqqqolIUAAAAAMRaq+GoV69eWrNmTbP71qxZo169ekWlKAAAAACItVbD0ZQpU/SXv/xFK1eulN/vlyT5/X6tXLlSzzzzjKZMmRKTIgEAAAAg2lps5S1JZ599tg4fPqwnn3xStbW1Sk5O1tGjR+VwODRt2jSdffbZsaoTAAAAAKKq1XAkSVOnTtXEiRO1ZcsWlZeXKzExUfn5+XK5XLGoDwAAAABios1wJEkul6vFrnUAAAAAcCJodc0RAAAAAJwsCEcAAAAAIMIRAAAAAEgiHAEAAACAJMIRAAAAAEgiHAEAAACAJMIRAAAAAEiK8D5HHeGLL77QwoUL5ff7NWnSJF1++eVh+99//3397//+ryQpLts3cs4AABdtSURBVC5ON9xwg/r27Rur8gAAAACc5GIycuT3+7VgwQL98pe/1MMPP6wPP/xQe/bsCTsmKytLv/nNbzR37lxdccUV+stf/hKL0gAAAABAUozC0bZt25STk6Ps7GzZbDaNHz9eq1atCjtm0KBBSkxMlCTl5eWptLQ0FqUBAAAAgKQYTasrKyuT2+0OPXe73dq6dWuLx7/zzjs6/fTTm923fPlyLV++XJI0Z84cZWRkdGyx34DNZutS9ZxouL7RxzWOPq5x9HGNo49rHF1c3+jjGkdfd73GMQlHpmk22WYYRrPHrl+/Xu+++65++9vfNru/sLBQhYWFoeclJSUdU2QHyMjI6FL1nGi4vtHHNY4+rnH0cY2jj2scXVzf6OMaR19XusY9e/aM+NiYTKtzu91h0+RKS0uVlpbW5Lhdu3bp6aef1s9+9jMlJSXFojQAAAAAkBSjcDRgwADt27dPBw8elNfr1YoVKzR69OiwY0pKSjR37lzddttt7Up3AAAAANARYjKtzmq1aubMmZo9e7b8fr8mTJig3r17a9myZZKkyZMn65VXXlF5ebnmz58fes2cOXNiUR4AAAAAxO4+RyNHjtTIkSPDtk2ePDn0+KabbtJNN90Uq3IAAAAAIExMptUBAAAAQFdHOAIAAAAAEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQJJk6+wCAAAA/n979x4cVX3+cfy9uSckhGyCXCKpIBcJJBMQCGhBSZaEABZqCYhCxyEol7SAaCQ4WtpBkUtQSicMNFCcdrS2/kbLcBFTmFCqWJAGRUAMIAUsJEA2hJBkwc2e3x+WrduEJLK7SRY+r3/I2fM93/Pss88fPHu+e45IW2cYBjabDYfDgclkau1w2ryysjKuXbvWYuczDAM/Pz9CQkLc+nzUHImIiIiINMFmsxEYGEhAgP773BwBAQH4+/u36Dntdjs2m43Q0NBbnkPL6kREREREmuBwONQYtXEBAQE4HA635lBzJCIiIiLSBC2l8w3ufk5qf0VERERE2jir1crkyZMBuHjxIv7+/pjNZgC2bdtGUFBQk3M888wzZGdn07Nnz5uOeeONN2jfvj2PPvqoZwL3MWqORERERETaOLPZzF//+lcAVq1aRbt27Zg1a5bLGMMwnDcmaMjrr7/e5HmefPJJt2P1ZVpWJyIiIiLiBcbJYzi2v4Nx8pjXznHq1ClSUlJYuHAh6enplJWV8fzzz5ORkcHIkSNdGqIJEyZw+PBh7HY7ffv2ZenSpVgsFh555BEuXboEwPLlyykoKHCOX7p0KWPHjmX48OF88sknANTU1PDUU09hsViYM2cOGRkZHD58uF5seXl5jBkzxhmfYRgAnDx5kszMTCwWC+np6Zw9exaANWvWkJqaisViYdmyZV7LWWN05UhERERE5HtwvF2AcfZU44Nqa+DrU2AYGCYT3N0dQsNuOtzUrTt+jz11S/GUlJTw2muvsXz5cgAWLVpEVFQUdrudzMxMxo4dS+/evV2OuXLlCkOHDuWFF17gl7/8JW+//TY/+9nP6s1tGAbbtm2jsLCQ1atX8+abb/K73/2Ojh07UlBQwJEjRxg9enSDcWVlZfHcc89hGAbZ2dkUFRWRkpJCdnY2CxYsIC0tDZvNhmEYFBYWUlRUxNatWwkNDaWiouKWcuEuNUciIiIiIp5WWw3/uVKCYXy73Uhz5I4f/OAHJCUlObc3b97MH//4R+rq6igtLaWkpKRecxQSEkJKSgoAiYmJ7Nu3r8G5MzIyAEhISHBe4dm/fz/Z2dkA9OvXjz59+jR47Icffsi6deu4du0aVquVxMREBg4ciNVqJS0tzRnHjbGPPfaY8zbcUVFRt5QLd6k5EhERERH5Hppzhcc4eQzHqhehzg7+AfjNeBbTvfd5JZ6wsP82XV999RUbNmxg27ZtREZG8vOf/7zBh7F+9wYO/v7+1NXVNTj3jXHfHXNjeVxjampqePHFF9mxYwddunRh+fLl2Gw2oOE7yjVnzpag3xyJiIiIiHiY6d778Hv2ZUzjn/j2Xy81Rv/r6tWrhIeHExERQVlZGbt37/b4OYYMGcKWLVsA+OKLLygpKak3xmaz4efnh9ls5urVq2zfvh2ADh06YDabKSwsdI6rra1lxIgRvP3229TW1gJoWZ2IiIiIyO3EdO99LdYU3ZCQkECvXr1ISUkhLi6OwYMHe/wc06dPZ968eVgsFvr370+fPn1o3769yxiz2UxmZiYpKSncfffdDBgwwLnvN7/5Dbm5uaxYsYLAwEAKCgoYNWoUR48eZcyYMQQEBDBq1Cief/55j8feFJPRVq5h3aJz5861dghOMTExzjt9iOcpv96nHHufcux9yrH3Kcfepfx6363kuKamxmX52p3Mbrdjt9sJCQnhq6++4vHHH+fDDz8kIOC/110CAgKw2+0tHltDn1PXrl2bfbyuHImIiIiISLNVV1czefJkZ/OzfPlyl8bIl90e70JERERERFpEZGQkO3bsaO0wvEI3ZBAREREREUHNkYiIiIiICKDmSEREREREBFBzJCIiIiIiAqg5EhERERFp8yZOnFjvga4FBQUsWrSo0eN69eoFQGlpKU899dRN5/7ss88anaegoMD5gFaAadOmUVlZ2YzIfYuaIxERERGRNm78+PFs3rzZ5bXNmzczYcKEZh3fuXNnCgoKbvn8GzZscGmO/vCHPxAZGXnL87VVao5ERERERLzg2MVa/u9wOccu1jY9uAljx45l586dXLt2DYCzZ89SVlbGkCFDqK6uZtKkSaSnp5OamsoHH3xQ7/izZ8+SkpICQG1tLbNnz8ZisTBr1ixsNptzXG5uLhkZGYwcOZK8vDwANm7cSFlZGZmZmUycOBGA5ORkrFYrAOvXryclJYWUlBRnA3bmzBkeeughcnJyGDlyJFOmTHFprm4oLCxk3LhxpKWlMXnyZC5evAh8+yylZ555htTUVCwWC9u2bQOgqKiI9PR0LBYLkyZNcjuv/0vPORIRERER+R42HCjjVIWt0TE139RxquI6BmACukcFERbof9Px3aNCmDGo0033m81mkpKS2L17N+np6WzevJkf/ehHmEwmgoOD2bhxIxEREVitVh555BHS0tIwmUwNzvX73/+e0NBQdu7cydGjRxk9erRz38KFC4mKiqKuro7Jkydz9OhRsrKy+O1vf8s777yD2Wx2mevQoUP8+c9/ZuvWrRiGwbhx4xg2bBhms5lTp06Rn5/PypUrmTlzJtu3b+cnP/mJy/FDhgxhy5YtmEwm3nrrLdauXcvixYtZvXo1ERER7Nq1C4DLly9TXl5OTk4O7777LnFxcVRUVDT6GdwKNUciIiIiIh5Wfd2B8Z+/jf9sN9YcNceECRPYvHmzszl67bXXvp3fMFi2bBn79u3DZDJRWlrKxYsXueuuuxqcZ9++fUyfPh2A+Ph4+vbt69y3ZcsW3nzzTerq6igrK+P48ePEx8ffNKb9+/czevRowsLCAMjIyGDfvn1kZGTQrVs3+vfvD0BiYiJnz56td/z58+eZPXs2Fy5c4Pr168TFxQHw97//nbVr1zrHdejQgcLCQoYOHeocExUV1ezcNZeaIxERERGR76GxKzw3HLtYy0u7zmB3GAT4mVjwYCz3dQx167yjR4/mV7/6FZ9//jk2m42EhAQA3n33XcrLy3n//fcJDAwkOTnZufzuZhq6qnTmzBnWr1/Ptm3b6NChA/Pnz3dZctcQwzBuui84ONj5t7+/f4NzvfTSSzz99NOkpaWxd+9el4avoRhvdjXMU/SbIxERERERD7uvYyhLUuN4IrEjS1Lj3G6MANq1a8ewYcNYsGCBy40YqqqqiImJITAwkI8++oivv/660XmSk5N57733ADh27BhffPGFc57Q0FDat2/PxYsXKSoqch4THh7O1atX6801dOhQPvjgA2pra6mpqWHHjh0kJyc3+z1duXKFzp07A/DOO+84X3/ooYfYtGmTc/vy5cvcf//9fPzxx5w5cwbAK8vq1ByJiIiIiHjBfR1Dmdg/2iON0Q0TJkzg6NGjjB8/3vnao48+ymeffUZGRgbvvfcePXv2bHSOn/70p1RXV2OxWFi7di1JSUkA9OvXj/79+zNy5EgWLFjA4MGDncc88cQTTJ061XlDhhsSEhLIzMxk7NixjBs3jilTpjiX0jXHs88+y8yZM/nxj3/s8numefPmUVlZSUpKChaLhb179xIdHc2KFSuYMWMGFouF2bNnN/s8zWUyGrsW5gPOnTvX2iE4xcTEcOnSpdYO47al/Hqfcux9yrH3Kcfepxx7l/LrfbeS45qaGufvaqRpAQEB2O32Fj9vQ59T165dm328rhyJiIiIiIig5khERERERARQcyQiIiIiIgKoORIRERERaZKP/0z/juHu56TmSERERESkCX5+fq1ygwFpPrvdjp+fe+2NHgIrIiIiItKEkJAQbDYb165d8/qDSG8HwcHBTT6I1pMMw8DPz4+QkBC35mmx5ujTTz9l06ZNOBwOUlNTXR5cBd++oU2bNnHw4EGCg4OZM2cOPXr0aKnwRERERERuymQyERrquecV3e589Zb0LbKszuFwsHHjRl544QVef/31Bp/ce/DgQUpLS1mzZg1PP/00GzZsaInQREREREREgBZqjk6cOEHnzp3p1KkTAQEBPPDAA3zyyScuYw4cOMCIESMwmUz07t2b6upqKioqWiI8ERERERGRlmmOrFYr0dHRzu3o6GisVmu9MTExMY2OERERERER8ZYW+c1RQ7fU+98fsjVnDMDOnTvZuXMnAMuWLaNr164eitIz2lo8txvl1/uUY+9Tjr1POfY+5di7lF/vU469zxdz3CJXjqKjoykvL3dul5eXExUVVW/Md3+01dAYAIvFwrJly1i2bJn3Ar5Fubm5rR3CbU359T7l2PuUY+9Tjr1POfYu5df7lGPv89Uct0hzdO+993L+/HkuXLiA3W5n7969DBo0yGXMoEGD2LNnD4ZhUFJSQlhYWIPNkYiIiIiIiDe0yLI6f39/pk+fziuvvILD4WDkyJF069aNwsJCANLS0hgwYADFxcXMnTuXoKAg5syZ0xKhiYiIiIiIAC34nKOBAwcycOBAl9fS0tKcf5tMJmbMmNFS4XiFxWJp7RBua8qv9ynH3qcce59y7H3KsXcpv96nHHufr+bYZDR0JwQREREREZE7TIv85khERERERKSta7FldbeLtWvXUlxcTGRkJKtWraq33zAMNm3axMGDBwkODmbOnDn06NGjFSL1XU3l+MiRI6xYsYK77roLgOTkZCZOnNjSYfqsS5cukZ+fz+XLlzGZTFgsFsaMGeMyRnXsnubkWHXsnuvXr7N48WLsdjt1dXUMHTqUSZMmuYxRHd+65uRXNewZDoeD3NxczGZzvbt7qYY9o7Ecq47dl52dTUhICH5+fvj7+9e7o7Sv1bGao+/p4YcfZvTo0eTn5ze4/+DBg5SWlrJmzRqOHz/Ohg0bWLp0aQtH6duayjFA3759ffYWka3N39+fadOm0aNHD2pra8nNzSUxMZG7777bOUZ17J7m5BhUx+4IDAxk8eLFhISEYLfb+cUvfkFSUhK9e/d2jlEd37rm5BdUw56wfft2YmNjqa2trbdPNewZjeUYVMeesHjxYtq3b9/gPl+rYy2r+57i4+MJDw+/6f4DBw4wYsQITCYTvXv3prq6moqKihaM0Pc1lWNxT1RUlPMbm9DQUGJjY7FarS5jVMfuaU6OxT0mk4mQkBAA6urqqKurq/fgcNXxrWtOfsV95eXlFBcXk5qa2uB+1bD7msqxeJ+v1bGuHHmY1WolJibGuR0dHY3VatUzmzyspKSEnJwcoqKimDZtGt26dWvtkHzShQsXOHXqFD179nR5XXXsOTfLMaiO3eVwOFi4cCGlpaWkp6fTq1cvl/2qY/c0lV9QDbvrjTfeYOrUqTe9oqEadl9TOQbVsSe88sorAIwaNareXep8rY7VHHlYQzf/07dtntW9e3fWrl1LSEgIxcXFrFy5kjVr1rR2WD7HZrOxatUqnnzyScLCwlz2qY49o7Ecq47d5+fnx8qVK6muriYvL48zZ84QFxfn3K86dk9T+VUNu+ef//wnkZGR9OjRgyNHjjQ4RjXsnubkWHXsviVLlmA2m6msrOTll1+ma9euxMfHO/f7Wh1rWZ2HRUdHc+nSJed2eXl5m+2MfVVYWJhzucfAgQOpq6vjypUrrRyVb7Hb7axatYrhw4eTnJxcb7/q2H1N5Vh17Dnt2rUjPj6eTz/91OV11bFn3Cy/qmH3fPnllxw4cIDs7GxWr17N4cOH6/2nXDXsnubkWHXsPrPZDEBkZCSDBw/mxIkTLvt9rY7VHHnYoEGD2LNnD4ZhUFJSQlhYWJsuAF90+fJl57cQJ06cwOFwEBER0cpR+Q7DMFi3bh2xsbGMGzeuwTGqY/c0J8eqY/dcuXKF6upq4Ns7q33++efExsa6jFEd37rm5Fc17J7HH3+cdevWkZ+fz/z58+nfvz9z5851GaMadk9zcqw6do/NZnMuWbTZbBw6dMjlCjP4Xh1rWd33tHr1ao4ePUpVVRWzZs1i0qRJ2O12ANLS0hgwYADFxcXMnTuXoKAg5syZ08oR+56mcvyPf/yDwsJC/P39CQoKYv78+W368mxb8+WXX7Jnzx7i4uLIyckBYMqUKc5vdVTH7mtOjlXH7qmoqCA/Px+Hw4FhGAwbNoz777+fwsJCQHXsrubkVzXsHaph71Mde05lZSV5eXnAtzdv+eEPf0hSUpJP17HJaGghoIiIiIiIyB1Gy+pERERERERQcyQiIiIiIgKoORIREREREQHUHImIiIiIiABqjkRERERERAA1RyIicgebNGkSpaWlrR2GiIi0EXrOkYiItBnZ2dlcvnwZP7//fnf38MMPk5WV1YpRiYjInULNkYiItCkLFy4kMTGxtcMQEZE7kJojERFp83bv3s2uXbvo3r07f/vb34iKiiIrK4uEhAQArFYrBQUFHDt2jPDwcMaPH4/FYgHA4XDwl7/8haKiIiorK+nSpQs5OTnExMQAcOjQIZYuXUpVVRUPPvggWVlZmEymVnuvIiLSetQciYiITzh+/DjJycls3LiR/fv3k5eXR35+PuHh4fz617+mW7durF+/nnPnzrFkyRI6depEQkICW7du5aOPPmLRokV06dKF06dPExwc7Jy3uLiYV199ldraWhYuXMigQYNISkpqxXcqIiKtRc2RiIi0KStXrsTf39+5PXXqVAICAoiMjGTs2LGYTCYeeOABtmzZQnFxMfHx8Rw7dozc3FyCgoK45557SE1NZc+ePSQkJLBr1y6mTp1K165dAbjnnntczjdhwgTatWtHu3bt6NevH//617/UHImI3KHUHImISJuSk5NT7zdHu3fvxmw2uyx369ixI1arlYqKCsLDwwkNDXXui4mJ4eTJkwCUl5fTqVOnm56vQ4cOzr+Dg4Ox2WyeeisiIuJjdCtvERHxCVarFcMwnNuXLl3CbDYTFRXF1atXqa2trbcPIDo6mrKyshaPV0REfI+aIxER8QmVlZW8//772O12Pv74Y/79738zYMAAYmJi6NOnD2+99RbXr1/n9OnTFBUVMXz4cABSU1P505/+xPnz5zEMg9OnT1NVVdXK70ZERNoiLasTEZE2Zfny5S7POUpMTGTw4MH06tWL8+fPk5WVRYcOHViwYAEREREAzJs3j4KCAmbOnEl4eDiZmZnOpXnjxo3jm2++4eWXX6aqqorY2Fiee+65VnlvIiLStpmM765REBERaYNu3Mp7yZIlrR2KiIjcxrSsTkREREREBDVHIiIiIiIigJbViYiIiIiIALpyJCIiIiIiAqg5EhERERERAdQciYiIiIiIAGqOREREREREADVHIiIiIiIigJojERERERERAP4fYG5dgu8SdXgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The TensorFlow embedding projector\n",
    "\n",
    "The Tensorflow embedding projector can be found [here](https://projector.tensorflow.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the embedding layer's weights from the trained model\n",
    "\n",
    "weights = model.layers[1].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the word Embeddings to tsv files\n",
    "# Two files: \n",
    "#     one contains the embedding labels (meta.tsv),\n",
    "#     one contains the embeddings (vecs.tsv)\n",
    "\n",
    "import io\n",
    "from os import path\n",
    "\n",
    "out_v = io.open(path.join('data', 'vecs.tsv'), 'w', encoding='utf-8')\n",
    "out_m = io.open(path.join('data', 'meta.tsv'), 'w', encoding='utf-8')\n",
    "\n",
    "k = 0\n",
    "\n",
    "for word, token in word_index.items():\n",
    "    if k != 0:\n",
    "        out_m.write('\\n')\n",
    "        out_v.write('\\n')\n",
    "    \n",
    "    out_v.write('\\t'.join([str(x) for x in weights[token]]))\n",
    "    out_m.write(word)\n",
    "    k += 1\n",
    "    \n",
    "out_v.close()\n",
    "out_m.close()\n",
    "# beware large collections of embeddings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_5\"></a>\n",
    "## Recurrent neural network layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize and pass an input to a SimpleRNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SimpleRNN layer and test it\n",
    "\n",
    "simplernn_layer = tf.keras.layers.SimpleRNN(units=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=13220, shape=(1, 16), dtype=float32, numpy=\n",
       "array([[ 0.90326613, -1.        ,  1.        , -1.        ,  0.99641204,\n",
       "         1.        ,  0.99999964, -1.        ,  1.        , -1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        -1.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that only the final cell output is returned\n",
    "\n",
    "sequence = tf.constant([[[1., 1.], [2., 2.], [56., -100.]]])\n",
    "layer_output = simplernn_layer(sequence)\n",
    "layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and transform the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset(maxlen=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word index using get_imdb_word_index()\n",
    "\n",
    "imdb_word_index = get_imdb_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a recurrent neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum index value\n",
    "\n",
    "max_index_value = max(imdb_word_index.values())\n",
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential, build the model:\n",
    "# 1. Embedding.\n",
    "# 2. LSTM.\n",
    "# 3. Dense.\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1, \n",
    "                              output_dim=embedding_dim,\n",
    "                              mask_zero=True),\n",
    "    tf.keras.layers.LSTM(units=16),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with binary cross-entropy loss\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              metrics=['accuracy'], \n",
    "              optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 525s 21ms/sample - loss: 0.3866 - accuracy: 0.8243\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 539s 22ms/sample - loss: 0.2252 - accuracy: 0.9146\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 531s 21ms/sample - loss: 0.1775 - accuracy: 0.9347\n"
     ]
    }
   ],
   "source": [
    "# Fit the model and save its training history\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=3, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ignore',\n",
       " 'the',\n",
       " 'bad',\n",
       " 'reviews',\n",
       " 'on',\n",
       " 'here',\n",
       " 'this',\n",
       " 'film',\n",
       " 'is',\n",
       " 'awesome',\n",
       " 'just',\n",
       " 'before',\n",
       " 'dawn',\n",
       " 'is',\n",
       " 'a',\n",
       " 'great',\n",
       " 'example',\n",
       " 'of',\n",
       " 'what',\n",
       " 'can',\n",
       " 'be',\n",
       " 'done',\n",
       " 'in',\n",
       " 'a',\n",
       " 'film',\n",
       " 'with',\n",
       " 'a',\n",
       " 'minimal',\n",
       " 'budget',\n",
       " 'if',\n",
       " 'you',\n",
       " 'have',\n",
       " 'a',\n",
       " 'dedicated',\n",
       " 'crew',\n",
       " 'decent',\n",
       " 'script',\n",
       " 'and',\n",
       " 'a',\n",
       " 'cool',\n",
       " 'idea',\n",
       " 'for',\n",
       " 'a',\n",
       " 'film',\n",
       " \"it's\",\n",
       " 'a',\n",
       " 'hell',\n",
       " 'of',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'fun',\n",
       " 'br',\n",
       " 'br',\n",
       " 'i',\n",
       " 'enjoyed',\n",
       " 'it',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'more',\n",
       " 'than',\n",
       " 'most',\n",
       " 'other',\n",
       " \"80's\",\n",
       " 'slashers',\n",
       " 'because',\n",
       " 'the',\n",
       " 'killer',\n",
       " 'is',\n",
       " 'so',\n",
       " 'unique',\n",
       " 'wrong',\n",
       " 'turn',\n",
       " 'ripped',\n",
       " 'this',\n",
       " 'movie',\n",
       " 'off',\n",
       " 'something',\n",
       " 'fierce',\n",
       " \"there's\",\n",
       " 'plenty',\n",
       " 'of',\n",
       " 'blood',\n",
       " 'and',\n",
       " 'scares',\n",
       " 'my',\n",
       " 'girlfriend',\n",
       " 'was',\n",
       " 'freaked',\n",
       " 'out',\n",
       " 'and',\n",
       " 'she',\n",
       " 'watches',\n",
       " 'almost',\n",
       " 'everything',\n",
       " 'with',\n",
       " 'me',\n",
       " 'and',\n",
       " \"doesn't\",\n",
       " \"it's\",\n",
       " 'got',\n",
       " 'that',\n",
       " 'creepiness',\n",
       " 'to',\n",
       " 'it',\n",
       " 'br',\n",
       " 'br',\n",
       " \"i'd\",\n",
       " 'say',\n",
       " 'that',\n",
       " 'just',\n",
       " 'before',\n",
       " 'dawn',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'early',\n",
       " \"80's\",\n",
       " 'slasher',\n",
       " 'out',\n",
       " 'there',\n",
       " 'i',\n",
       " 'really',\n",
       " 'enjoyed',\n",
       " 'it',\n",
       " 'br',\n",
       " 'br',\n",
       " '8',\n",
       " 'out',\n",
       " 'of',\n",
       " '10',\n",
       " 'kids']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first test data example sentence\n",
    "# (invert the word index)\n",
    "\n",
    "inv_imdb_word_index = {value : key for key, value in imdb_word_index.items()}\n",
    "[inv_imdb_word_index[index] for index in x_test[0] if index > 2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9925252]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the model prediction using model.predict()\n",
    "\n",
    "model.predict(x_test[None, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the corresponding label\n",
    "\n",
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_6\"></a>\n",
    "## Stacked RNNs and the Bidirectional wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and transform the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset(num_words=5000, maxlen=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word index using get_imdb_word_index()\n",
    "\n",
    "imdb_word_index = get_imdb_word_index(num_words=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build stacked and bidirectional recurrent models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum index value and specify an embedding dimension\n",
    "\n",
    "max_index_value = max(imdb_word_index.values())\n",
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential, build a stacked LSTM model via return_sequences=True\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1,\n",
    "                              output_dim=embedding_dim,\n",
    "                              mask_zero=True),\n",
    "    tf.keras.layers.LSTM(units=32, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(units=32, return_sequences=False),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential, build a bidirectional RNN with merge_mode='sum'\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1,\n",
    "                              output_dim=embedding_dim,\n",
    "                              mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(layer=tf.keras.layers.LSTM(units=8),\n",
    "                                 merge_mode='sum',\n",
    "                                 backward_layer=tf.keras.layers.GRU(units=8, go_backwards=True)),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model featuring both stacked recurrent layers and a bidirectional layer\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1,\n",
    "                              output_dim=embedding_dim,\n",
    "                              mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=8, return_sequences=True),\n",
    "                                 merge_mode='concat'),\n",
    "    tf.keras.layers.GRU(units=8, return_sequences=False),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model, saving its history\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=3, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
